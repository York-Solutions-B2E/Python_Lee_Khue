{
    "kind": "Listing",
    "data": {
        "after": "t3_1927zi6",
        "dist": 26,
        "modhash": "",
        "geo_filter": null,
        "children": [
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n\nThread will stay alive until next one so keep posting after the date in the title.\n\nThanks to everyone for answering questions in the previous thread!",
                    "author_fullname": "t2_6l4z3",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[D] Simple Questions Thread",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_18vao7j",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.8,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 6,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 6,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": true,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1704038423.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!&lt;/p&gt;\n\n&lt;p&gt;Thread will stay alive until next one so keep posting after the date in the title.&lt;/p&gt;\n\n&lt;p&gt;Thanks to everyone for answering questions in the previous thread!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": "new",
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "18vao7j",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "AutoModerator",
                    "discussion_type": null,
                    "num_comments": 43,
                    "send_replies": false,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": true,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/",
                    "subreddit_subscribers": 2854921,
                    "created_utc": 1704038423.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "I'm currently applying to jobs so I'm interested to hear the harsh reality of what it's like.",
                    "author_fullname": "t2_mfvu5nmtd",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Be Honest, What Sucks About Being a CV Engineer? [D]",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_192hvop",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.84,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 33,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 33,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1704815756.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently applying to jobs so I&amp;#39;m interested to hear the harsh reality of what it&amp;#39;s like.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "192hvop",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "vanteworldinfinity",
                    "discussion_type": null,
                    "num_comments": 30,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/192hvop/be_honest_what_sucks_about_being_a_cv_engineer_d/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/192hvop/be_honest_what_sucks_about_being_a_cv_engineer_d/",
                    "subreddit_subscribers": 2854921,
                    "created_utc": 1704815756.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "Hi all,\n\nDoes anyone have any concept of technical and business related gaps and weaknesses of this field? Things that if were possible or more efficient, would make projects and model optimal? For example (not necessarily a massive case anymore) lack of quality datasets. \n\nThanks big time!",
                    "author_fullname": "t2_vhqu7rh6",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "What are weaknesses of the field currently? [D]",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_192aj3h",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.86,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 46,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 46,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1704791212.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any concept of technical and business related gaps and weaknesses of this field? Things that if were possible or more efficient, would make projects and model optimal? For example (not necessarily a massive case anymore) lack of quality datasets. &lt;/p&gt;\n\n&lt;p&gt;Thanks big time!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "192aj3h",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "convolutionality",
                    "discussion_type": null,
                    "num_comments": 40,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/192aj3h/what_are_weaknesses_of_the_field_currently_d/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/192aj3h/what_are_weaknesses_of_the_field_currently_d/",
                    "subreddit_subscribers": 2854921,
                    "created_utc": 1704791212.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "Paper: [https://arxiv.org/abs/2305.14292v2](https://arxiv.org/abs/2305.14292v2) \n\nGithub: [https://github.com/stanford-oval/WikiChat](https://github.com/stanford-oval/WikiChat) \n\nAbstract:\n\n&gt;This paper presents the first few-shot LLM-based chatbot that almost never hallucinates and has high conversationality and low latency. WikiChat is grounded on the English Wikipedia, the largest curated free-text corpus.  \n&gt;  \n&gt;WikiChat generates a response from an LLM, retains only the grounded facts, and combines them with additional information it retrieves from the corpus to form factual and engaging responses. **We distill WikiChat based on GPT-4 into a 7B-parameter LLaMA model with minimal loss of quality, to significantly improve its latency, cost and privacy, and facilitate research and deployment.**  \n&gt;  \n&gt;Using a novel hybrid human-and-LLM evaluation methodology, we show that our best system achieves 97.3% factual accuracy in simulated conversations. It significantly outperforms all retrieval-based and LLM-based baselines, and by 3.9%, 38.6% and 51.0% on head, tail and recent knowledge compared to GPT-4. Compared to previous state-of-the-art retrieval-based chatbots, WikiChat is also significantly more informative and engaging, just like an LLM.  \n&gt;  \n&gt;**WikiChat achieves 97.9% factual accuracy in conversations with human users about recent topics, 55.0% better than GPT-4,** while receiving significantly higher user ratings and more favorable comments. \n\nhttps://preview.redd.it/9mhpdh300bbc1.jpg?width=1225&amp;format=pjpg&amp;auto=webp&amp;s=cb64b717e920d7bf727782f7c803500ae838d6ef\n\nhttps://preview.redd.it/5dxesl200bbc1.jpg?width=862&amp;format=pjpg&amp;auto=webp&amp;s=b6de0cda980eec3cf3484ff1f9cd6dc1acf13505\n\nhttps://preview.redd.it/j387vl200bbc1.jpg?width=914&amp;format=pjpg&amp;auto=webp&amp;s=736fb922c1f98f4c7b132f1c153f4653a8b85441\n\nhttps://preview.redd.it/3hnxqi200bbc1.jpg?width=923&amp;format=pjpg&amp;auto=webp&amp;s=95b40a9cf67d7f3729dae85878db67a262cc5201",
                    "author_fullname": "t2_9l187vq4",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[R] WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia - Achieves 97.9% factual accuracy in conversations with human users about recent topics, 55.0% better than GPT-4! - Stanford University 2023",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "three",
                    "downs": 0,
                    "thumbnail_height": 95,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "media_metadata": {
                        "9mhpdh300bbc1": {
                            "status": "valid",
                            "e": "Image",
                            "m": "image/jpg",
                            "p": [
                                {
                                    "y": 73,
                                    "x": 108,
                                    "u": "https://preview.redd.it/9mhpdh300bbc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e110c24fa461ba3babb0de1990f44080cca69a62"
                                },
                                {
                                    "y": 147,
                                    "x": 216,
                                    "u": "https://preview.redd.it/9mhpdh300bbc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=605694bd75c9d6aa802242611b067c6af158c495"
                                },
                                {
                                    "y": 218,
                                    "x": 320,
                                    "u": "https://preview.redd.it/9mhpdh300bbc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9dbbd6480f1444f4aeef04c3d5a05aefd712aa3b"
                                },
                                {
                                    "y": 436,
                                    "x": 640,
                                    "u": "https://preview.redd.it/9mhpdh300bbc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=942c2fe458ce758c190ddc9dee37dd799fd90a5c"
                                },
                                {
                                    "y": 655,
                                    "x": 960,
                                    "u": "https://preview.redd.it/9mhpdh300bbc1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f18c1d04c3607f6d795ccb83f514798fb43d9abb"
                                },
                                {
                                    "y": 737,
                                    "x": 1080,
                                    "u": "https://preview.redd.it/9mhpdh300bbc1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a3e78aa8c7b71cba79183c2f782dc0fe0d58d336"
                                }
                            ],
                            "s": {
                                "y": 836,
                                "x": 1225,
                                "u": "https://preview.redd.it/9mhpdh300bbc1.jpg?width=1225&amp;format=pjpg&amp;auto=webp&amp;s=cb64b717e920d7bf727782f7c803500ae838d6ef"
                            },
                            "id": "9mhpdh300bbc1"
                        },
                        "3hnxqi200bbc1": {
                            "status": "valid",
                            "e": "Image",
                            "m": "image/jpg",
                            "p": [
                                {
                                    "y": 39,
                                    "x": 108,
                                    "u": "https://preview.redd.it/3hnxqi200bbc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ac93e56314faa2e82cdfd1ca9dff7257294980d2"
                                },
                                {
                                    "y": 78,
                                    "x": 216,
                                    "u": "https://preview.redd.it/3hnxqi200bbc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d3af903413d040d2df735fc068f926f7adc6600a"
                                },
                                {
                                    "y": 115,
                                    "x": 320,
                                    "u": "https://preview.redd.it/3hnxqi200bbc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7bc1cb2413081e300b7558251a4d04dcb81b2c7d"
                                },
                                {
                                    "y": 231,
                                    "x": 640,
                                    "u": "https://preview.redd.it/3hnxqi200bbc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=103e1e8ad01c30920ed620592df48457e4440458"
                                }
                            ],
                            "s": {
                                "y": 334,
                                "x": 923,
                                "u": "https://preview.redd.it/3hnxqi200bbc1.jpg?width=923&amp;format=pjpg&amp;auto=webp&amp;s=95b40a9cf67d7f3729dae85878db67a262cc5201"
                            },
                            "id": "3hnxqi200bbc1"
                        },
                        "j387vl200bbc1": {
                            "status": "valid",
                            "e": "Image",
                            "m": "image/jpg",
                            "p": [
                                {
                                    "y": 61,
                                    "x": 108,
                                    "u": "https://preview.redd.it/j387vl200bbc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=10e81711110e2c9cf8758802fe40ee8c3e5f1ff1"
                                },
                                {
                                    "y": 122,
                                    "x": 216,
                                    "u": "https://preview.redd.it/j387vl200bbc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0f25a476c3d3765183a35dbbce92b614874429da"
                                },
                                {
                                    "y": 181,
                                    "x": 320,
                                    "u": "https://preview.redd.it/j387vl200bbc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a8c1c2f3a630cb5735fa34e34c07b5246e52409e"
                                },
                                {
                                    "y": 362,
                                    "x": 640,
                                    "u": "https://preview.redd.it/j387vl200bbc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=03835af49eb64651a429dfe999b5d229f7e6eb67"
                                }
                            ],
                            "s": {
                                "y": 518,
                                "x": 914,
                                "u": "https://preview.redd.it/j387vl200bbc1.jpg?width=914&amp;format=pjpg&amp;auto=webp&amp;s=736fb922c1f98f4c7b132f1c153f4653a8b85441"
                            },
                            "id": "j387vl200bbc1"
                        },
                        "5dxesl200bbc1": {
                            "status": "valid",
                            "e": "Image",
                            "m": "image/jpg",
                            "p": [
                                {
                                    "y": 97,
                                    "x": 108,
                                    "u": "https://preview.redd.it/5dxesl200bbc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=479431d35ae708050e14c041de0b0d131a4f4bc0"
                                },
                                {
                                    "y": 195,
                                    "x": 216,
                                    "u": "https://preview.redd.it/5dxesl200bbc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4cecdf93af061ccc4e19ceafc0f8a80c3fc7a9c6"
                                },
                                {
                                    "y": 289,
                                    "x": 320,
                                    "u": "https://preview.redd.it/5dxesl200bbc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0c60760169c2874a818758975e8cf3e77befcf4a"
                                },
                                {
                                    "y": 578,
                                    "x": 640,
                                    "u": "https://preview.redd.it/5dxesl200bbc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f28642b77611331703a07c8ca554ce7fdd4b7d1a"
                                }
                            ],
                            "s": {
                                "y": 779,
                                "x": 862,
                                "u": "https://preview.redd.it/5dxesl200bbc1.jpg?width=862&amp;format=pjpg&amp;auto=webp&amp;s=b6de0cda980eec3cf3484ff1f9cd6dc1acf13505"
                            },
                            "id": "5dxesl200bbc1"
                        }
                    },
                    "name": "t3_1920hky",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.95,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 165,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": 140,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Research",
                    "can_mod_post": false,
                    "score": 165,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "https://a.thumbs.redditmedia.com/pL9mqZoWevq5qGU-OmKchuLdzRggmp7vVcnZImcdFn0.jpg",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1704758860.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Paper: &lt;a href=\"https://arxiv.org/abs/2305.14292v2\"&gt;https://arxiv.org/abs/2305.14292v2&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Github: &lt;a href=\"https://github.com/stanford-oval/WikiChat\"&gt;https://github.com/stanford-oval/WikiChat&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Abstract:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;This paper presents the first few-shot LLM-based chatbot that almost never hallucinates and has high conversationality and low latency. WikiChat is grounded on the English Wikipedia, the largest curated free-text corpus.  &lt;/p&gt;\n\n&lt;p&gt;WikiChat generates a response from an LLM, retains only the grounded facts, and combines them with additional information it retrieves from the corpus to form factual and engaging responses. &lt;strong&gt;We distill WikiChat based on GPT-4 into a 7B-parameter LLaMA model with minimal loss of quality, to significantly improve its latency, cost and privacy, and facilitate research and deployment.&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;p&gt;Using a novel hybrid human-and-LLM evaluation methodology, we show that our best system achieves 97.3% factual accuracy in simulated conversations. It significantly outperforms all retrieval-based and LLM-based baselines, and by 3.9%, 38.6% and 51.0% on head, tail and recent knowledge compared to GPT-4. Compared to previous state-of-the-art retrieval-based chatbots, WikiChat is also significantly more informative and engaging, just like an LLM.  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;WikiChat achieves 97.9% factual accuracy in conversations with human users about recent topics, 55.0% better than GPT-4,&lt;/strong&gt; while receiving significantly higher user ratings and more favorable comments. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/9mhpdh300bbc1.jpg?width=1225&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=cb64b717e920d7bf727782f7c803500ae838d6ef\"&gt;https://preview.redd.it/9mhpdh300bbc1.jpg?width=1225&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=cb64b717e920d7bf727782f7c803500ae838d6ef&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/5dxesl200bbc1.jpg?width=862&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=b6de0cda980eec3cf3484ff1f9cd6dc1acf13505\"&gt;https://preview.redd.it/5dxesl200bbc1.jpg?width=862&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=b6de0cda980eec3cf3484ff1f9cd6dc1acf13505&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/j387vl200bbc1.jpg?width=914&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=736fb922c1f98f4c7b132f1c153f4653a8b85441\"&gt;https://preview.redd.it/j387vl200bbc1.jpg?width=914&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=736fb922c1f98f4c7b132f1c153f4653a8b85441&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/3hnxqi200bbc1.jpg?width=923&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=95b40a9cf67d7f3729dae85878db67a262cc5201\"&gt;https://preview.redd.it/3hnxqi200bbc1.jpg?width=923&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=95b40a9cf67d7f3729dae85878db67a262cc5201&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "1920hky",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Singularian2501",
                    "discussion_type": null,
                    "num_comments": 24,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/1920hky/r_wikichat_stopping_the_hallucination_of_large/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/1920hky/r_wikichat_stopping_the_hallucination_of_large/",
                    "subreddit_subscribers": 2854921,
                    "created_utc": 1704758860.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "Loks like Copilot Studio is being rolled out (https://www.microsoft.com/en-us/microsoft-copilot/microsoft-copilot-studio) with an impressive looking no code/out of the box RAG solution.\n\nThere is a phenomenal amount of development and activity in the Open Source RAG world (e.g Langchain, Llamaindex, etc), which I am a great supporter of FYI.\n\nHowever, what seems strange is that this no code out of the box solution (Copilot Studio - just as an example of one) seems overwhelmingly to be the better option if you wanted to build a RAG app i.e If you compare the cost to build and productionise a custom RAG app vs the cost of using Copilot Studio, it's almost an order of magnitude lower (no matter how you cut it with the developer time and duration). \n\nMy question is, it seems to me we are moving towards a situation where enterprise solutions will make custom RAG apps redundant (not in all cases of course, but most cases), however there seems to be very little discussion of this relative to the activity in the open source community. Do people agree this is a likely scenario? \n\nObviously there will be exceptions\u2026but on most use cases I don\u2019t see how you can compete with an instant/minimal setup, low cost, highly scalable RAG solution.",
                    "author_fullname": "t2_j1rufjwv",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[D] Are Custom LLM RAG apps going to become redundant?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1929n4f",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.92,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 36,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 36,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1704787385.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Loks like Copilot Studio is being rolled out (&lt;a href=\"https://www.microsoft.com/en-us/microsoft-copilot/microsoft-copilot-studio\"&gt;https://www.microsoft.com/en-us/microsoft-copilot/microsoft-copilot-studio&lt;/a&gt;) with an impressive looking no code/out of the box RAG solution.&lt;/p&gt;\n\n&lt;p&gt;There is a phenomenal amount of development and activity in the Open Source RAG world (e.g Langchain, Llamaindex, etc), which I am a great supporter of FYI.&lt;/p&gt;\n\n&lt;p&gt;However, what seems strange is that this no code out of the box solution (Copilot Studio - just as an example of one) seems overwhelmingly to be the better option if you wanted to build a RAG app i.e If you compare the cost to build and productionise a custom RAG app vs the cost of using Copilot Studio, it&amp;#39;s almost an order of magnitude lower (no matter how you cut it with the developer time and duration). &lt;/p&gt;\n\n&lt;p&gt;My question is, it seems to me we are moving towards a situation where enterprise solutions will make custom RAG apps redundant (not in all cases of course, but most cases), however there seems to be very little discussion of this relative to the activity in the open source community. Do people agree this is a likely scenario? &lt;/p&gt;\n\n&lt;p&gt;Obviously there will be exceptions\u2026but on most use cases I don\u2019t see how you can compete with an instant/minimal setup, low cost, highly scalable RAG solution.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "1929n4f",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Used-Ad-7734",
                    "discussion_type": null,
                    "num_comments": 10,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/1929n4f/d_are_custom_llm_rag_apps_going_to_become/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/1929n4f/d_are_custom_llm_rag_apps_going_to_become/",
                    "subreddit_subscribers": 2854921,
                    "created_utc": 1704787385.0,
                    "num_crossposts": 1,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "&amp;#x200B;\n\n[A Figma prototype for the website idea](https://preview.redd.it/acwzpkmo6gbc1.png?width=1440&amp;format=png&amp;auto=webp&amp;s=36583eabcb78cca5349a3b75df93a71d5ab02a73)\n\nSo I have an idea for a website that helps people explore complex topics from machine learning in an interactive way.\n\nTopics would include model architecture:\n\n* model architectures\n* methods for training and fine tuning models\n* novel approaches to improving model performance\n* basically anythinng that is discussed in research papers\n\nI would try to make it as interactive as possible so that people could form a deep understanding of the topics that interest them. I would also link to code and hugging face implementations so that people could get hands on experience with these topics themselves.\n\nThe goal is to help people better understand the research that is going on in the space and make it easy for them to get practical experience with the new technologies.\n\nWhat are your thoughts on the idea? What else should I consider? What are some obvious problems? Would you use/contribute to this if it existed?\n\n Any opinion at all will help me to clarify the idea, so please share! Thanks :)",
                    "author_fullname": "t2_9ir9i3i6",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[D] An idea for an interactive website that helps people explore and discover new ML concepts",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": 99,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "media_metadata": {
                        "acwzpkmo6gbc1": {
                            "status": "valid",
                            "e": "Image",
                            "m": "image/png",
                            "p": [
                                {
                                    "y": 76,
                                    "x": 108,
                                    "u": "https://preview.redd.it/acwzpkmo6gbc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=eea70a0ab925a5407f18ff15c121655afcb9bd83"
                                },
                                {
                                    "y": 153,
                                    "x": 216,
                                    "u": "https://preview.redd.it/acwzpkmo6gbc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d79e86cf3e7fb02b7b8ff22bc13a8caa2e274a33"
                                },
                                {
                                    "y": 227,
                                    "x": 320,
                                    "u": "https://preview.redd.it/acwzpkmo6gbc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=bc4307aa6cc4ee34c80a7f7b8f2a2549ea5c69d7"
                                },
                                {
                                    "y": 455,
                                    "x": 640,
                                    "u": "https://preview.redd.it/acwzpkmo6gbc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=760ce02d8f0bea500c2cbc0185db1062c5199f3c"
                                },
                                {
                                    "y": 682,
                                    "x": 960,
                                    "u": "https://preview.redd.it/acwzpkmo6gbc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=3f0b2a8457c4f371400a57f5d8ccc7d3ef1ee5c4"
                                },
                                {
                                    "y": 768,
                                    "x": 1080,
                                    "u": "https://preview.redd.it/acwzpkmo6gbc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a452e7861235269678882aadabaed238a6396dec"
                                }
                            ],
                            "s": {
                                "y": 1024,
                                "x": 1440,
                                "u": "https://preview.redd.it/acwzpkmo6gbc1.png?width=1440&amp;format=png&amp;auto=webp&amp;s=36583eabcb78cca5349a3b75df93a71d5ab02a73"
                            },
                            "id": "acwzpkmo6gbc1"
                        }
                    },
                    "name": "t3_192jxt8",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.83,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 4,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": 140,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 4,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "https://a.thumbs.redditmedia.com/KUlvZRr_ahI-x4Ntf3EgILrQHcIlZBtAzSxh2SfEC-8.jpg",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1704820714.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/acwzpkmo6gbc1.png?width=1440&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=36583eabcb78cca5349a3b75df93a71d5ab02a73\"&gt;A Figma prototype for the website idea&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;So I have an idea for a website that helps people explore complex topics from machine learning in an interactive way.&lt;/p&gt;\n\n&lt;p&gt;Topics would include model architecture:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;model architectures&lt;/li&gt;\n&lt;li&gt;methods for training and fine tuning models&lt;/li&gt;\n&lt;li&gt;novel approaches to improving model performance&lt;/li&gt;\n&lt;li&gt;basically anythinng that is discussed in research papers&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I would try to make it as interactive as possible so that people could form a deep understanding of the topics that interest them. I would also link to code and hugging face implementations so that people could get hands on experience with these topics themselves.&lt;/p&gt;\n\n&lt;p&gt;The goal is to help people better understand the research that is going on in the space and make it easy for them to get practical experience with the new technologies.&lt;/p&gt;\n\n&lt;p&gt;What are your thoughts on the idea? What else should I consider? What are some obvious problems? Would you use/contribute to this if it existed?&lt;/p&gt;\n\n&lt;p&gt;Any opinion at all will help me to clarify the idea, so please share! Thanks :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "192jxt8",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "IffyNibba01",
                    "discussion_type": null,
                    "num_comments": 2,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/192jxt8/d_an_idea_for_an_interactive_website_that_helps/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/192jxt8/d_an_idea_for_an_interactive_website_that_helps/",
                    "subreddit_subscribers": 2854921,
                    "created_utc": 1704820714.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "Hi! I\u2019d like to share marimo, an open-source reactive notebook for Python. It aims to solve many well-known problems with Jupyter notebooks, while giving you new capabilities: marimo notebooks are reproducible (no hidden state), git-friendly (stored as a Python file), executable as Python scripts, and deployable as web apps[.](http://apps.it/)\n\nGitHub Repo: [https://github.com/marimo-team/marimo](https://github.com/marimo-team/marimo)\n\nIn marimo, your notebook code, outputs, and program state are guaranteed to be consistent. Run a cell and marimo\u00a0*reacts*\u00a0by automatically running the cells that reference its variables. Delete a cell and marimo scrubs its variables from program memory, eliminating hidden state. If you are worried about accidentally triggering expensive computations, you can disable specific cells from auto-running.\n\nmarimo also comes with UI elements like sliders, a dataframe transformer, and interactive plots that are automatically synchronized with Python. Interact with an element and the cells that use it are automatically re-run with its latest value. Reactivity makes these UI elements substantially more useful than Jupyter widgets, not to mention easier to use.\n\nI chose to develop marimo because I believe that the ML community deserves a better programming environment to do research and communicate it. I\u2019ve seen lots of research start in Jupyter notebooks (much of my own has). I\u2019ve also seen lots of that same research fail to reproduce or get slowed down by hidden bugs, due to shortcomings inherent to Jupyter notebooks.\n\nI strongly believe that the quality of our work depends on the quality of our tools, and that the tools we use shape the way we think \u2014 better tools, for better minds. I worked at Google Brain as a software engineer in 2017-2018, when TensorFlow was transitioning to TensorFlow 2 and JAX was in its early stages. I saw firsthand the increase in productivity that PyTorch and JAX brought to our community, and later to my own research when I did a PhD at Stanford with Stephen Boyd. Our goal with marimo is to do something analogous but via a new programming environment.\n\nmarimo has been developed with the close input of scientists and engineers, and with inspiration from many tools, including Pluto.jl and streamlit. It\u2019s just two of us working on it \u2014 we open sourced it recently because we feel it\u2019s ready for broader use. Please try it out (pip install marimo &amp;&amp; marimo tutorial intro). We\u2019d really love any and all feedback you may have!",
                    "author_fullname": "t2_cggey",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[P] I built marimo \u2014 an open-source reactive Python notebook that\u2019s stored as a .py file, executable as a script, and deployable as an app.",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "four",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_191rdwq",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.98,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 202,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Project",
                    "can_mod_post": false,
                    "score": 202,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1704736841.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I\u2019d like to share marimo, an open-source reactive notebook for Python. It aims to solve many well-known problems with Jupyter notebooks, while giving you new capabilities: marimo notebooks are reproducible (no hidden state), git-friendly (stored as a Python file), executable as Python scripts, and deployable as web apps&lt;a href=\"http://apps.it/\"&gt;.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;GitHub Repo: &lt;a href=\"https://github.com/marimo-team/marimo\"&gt;https://github.com/marimo-team/marimo&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;In marimo, your notebook code, outputs, and program state are guaranteed to be consistent. Run a cell and marimo\u00a0&lt;em&gt;reacts&lt;/em&gt;\u00a0by automatically running the cells that reference its variables. Delete a cell and marimo scrubs its variables from program memory, eliminating hidden state. If you are worried about accidentally triggering expensive computations, you can disable specific cells from auto-running.&lt;/p&gt;\n\n&lt;p&gt;marimo also comes with UI elements like sliders, a dataframe transformer, and interactive plots that are automatically synchronized with Python. Interact with an element and the cells that use it are automatically re-run with its latest value. Reactivity makes these UI elements substantially more useful than Jupyter widgets, not to mention easier to use.&lt;/p&gt;\n\n&lt;p&gt;I chose to develop marimo because I believe that the ML community deserves a better programming environment to do research and communicate it. I\u2019ve seen lots of research start in Jupyter notebooks (much of my own has). I\u2019ve also seen lots of that same research fail to reproduce or get slowed down by hidden bugs, due to shortcomings inherent to Jupyter notebooks.&lt;/p&gt;\n\n&lt;p&gt;I strongly believe that the quality of our work depends on the quality of our tools, and that the tools we use shape the way we think \u2014 better tools, for better minds. I worked at Google Brain as a software engineer in 2017-2018, when TensorFlow was transitioning to TensorFlow 2 and JAX was in its early stages. I saw firsthand the increase in productivity that PyTorch and JAX brought to our community, and later to my own research when I did a PhD at Stanford with Stephen Boyd. Our goal with marimo is to do something analogous but via a new programming environment.&lt;/p&gt;\n\n&lt;p&gt;marimo has been developed with the close input of scientists and engineers, and with inspiration from many tools, including Pluto.jl and streamlit. It\u2019s just two of us working on it \u2014 we open sourced it recently because we feel it\u2019s ready for broader use. Please try it out (pip install marimo &amp;amp;&amp;amp; marimo tutorial intro). We\u2019d really love any and all feedback you may have!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "191rdwq",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "akshayka",
                    "discussion_type": null,
                    "num_comments": 33,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/191rdwq/p_i_built_marimo_an_opensource_reactive_python/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/191rdwq/p_i_built_marimo_an_opensource_reactive_python/",
                    "subreddit_subscribers": 2854921,
                    "created_utc": 1704736841.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "I've been looking into semantic search recently for a personal project and I came across the Google Cloud Platform \"Gecko\" embedding model which looks like it would be able to allow me to find similar products by comparing how similar their descriptions are.\n\nThe main issue that I'm seeing with semantic search is the requirement that the embedding model remains completely unchanged and still available because otherwise, I won't be able to measure the \"closeness\" of any new products. In that case, I would have to re-vectorise all of the products I've already vectorised because the vector space representations of different embedding models are different. Seems like it could be expensive and a massive time-suck.\n\nGiven Google's reputation for canning its old products, I don't want to jump into something that will be gone soon. Does Google have back compatibility for this kind of thing? Would I be better off going somewhere else or just giving up and hosting a pre-trained version of Word2Vec on GPC or AWS instead?",
                    "author_fullname": "t2_jmvygih",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[P] Does Google sunset their off-the-shelf models as well as their apps?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "four",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_192chr6",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 7,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Project",
                    "can_mod_post": false,
                    "score": 7,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1704799226.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been looking into semantic search recently for a personal project and I came across the Google Cloud Platform &amp;quot;Gecko&amp;quot; embedding model which looks like it would be able to allow me to find similar products by comparing how similar their descriptions are.&lt;/p&gt;\n\n&lt;p&gt;The main issue that I&amp;#39;m seeing with semantic search is the requirement that the embedding model remains completely unchanged and still available because otherwise, I won&amp;#39;t be able to measure the &amp;quot;closeness&amp;quot; of any new products. In that case, I would have to re-vectorise all of the products I&amp;#39;ve already vectorised because the vector space representations of different embedding models are different. Seems like it could be expensive and a massive time-suck.&lt;/p&gt;\n\n&lt;p&gt;Given Google&amp;#39;s reputation for canning its old products, I don&amp;#39;t want to jump into something that will be gone soon. Does Google have back compatibility for this kind of thing? Would I be better off going somewhere else or just giving up and hosting a pre-trained version of Word2Vec on GPC or AWS instead?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "192chr6",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "ojiber",
                    "discussion_type": null,
                    "num_comments": 6,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/192chr6/p_does_google_sunset_their_offtheshelf_models_as/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/192chr6/p_does_google_sunset_their_offtheshelf_models_as/",
                    "subreddit_subscribers": 2854921,
                    "created_utc": 1704799226.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "**Paper**: [https://www.nature.com/articles/s41593-023-01514-1](https://www.nature.com/articles/s41593-023-01514-1)\n\n**Preprint version(s)**: [https://www.biorxiv.org/content/10.1101/2022.05.17.492325](https://www.biorxiv.org/content/10.1101/2022.05.17.492325v2)\n\n**Code**: [https://github.com/YuhangSong/Prospective-Configuration](https://github.com/YuhangSong/Prospective-Configuration)\n\n**Abstract**:\n\n&gt;For both humans and machines, the essence of learning is to pinpoint  which components in its information processing pipeline are responsible  for an error in its output, a challenge that is known as \u2018credit  assignment\u2019. It has long been assumed that credit assignment is best  solved by backpropagation, which is also the foundation of modern  machine learning. Here, we set out a fundamentally different principle  on credit assignment called \u2018**prospective configuration**\u2019. In prospective  configuration, the network first infers the pattern of neural activity  that should result from learning, and then the synaptic weights are  modified to consolidate the change in neural activity. We demonstrate  that this distinct mechanism, in contrast to backpropagation, (1)  underlies learning in a well-established family of models of cortical  circuits, (2) enables learning that is more efficient and effective in  many contexts faced by biological organisms and (3) reproduces  surprising patterns of neural activity and behavior observed in diverse  human and rat learning experiments.",
                    "author_fullname": "t2_mveclxvsc",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[R] Inferring neural activity before plasticity as a foundation for learning beyond backpropagation",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "three",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_192an1m",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 11,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Research",
                    "can_mod_post": false,
                    "score": 11,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "self",
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1704791684.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Paper&lt;/strong&gt;: &lt;a href=\"https://www.nature.com/articles/s41593-023-01514-1\"&gt;https://www.nature.com/articles/s41593-023-01514-1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Preprint version(s)&lt;/strong&gt;: &lt;a href=\"https://www.biorxiv.org/content/10.1101/2022.05.17.492325v2\"&gt;https://www.biorxiv.org/content/10.1101/2022.05.17.492325&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Code&lt;/strong&gt;: &lt;a href=\"https://github.com/YuhangSong/Prospective-Configuration\"&gt;https://github.com/YuhangSong/Prospective-Configuration&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;For both humans and machines, the essence of learning is to pinpoint  which components in its information processing pipeline are responsible  for an error in its output, a challenge that is known as \u2018credit  assignment\u2019. It has long been assumed that credit assignment is best  solved by backpropagation, which is also the foundation of modern  machine learning. Here, we set out a fundamentally different principle  on credit assignment called \u2018&lt;strong&gt;prospective configuration&lt;/strong&gt;\u2019. In prospective  configuration, the network first infers the pattern of neural activity  that should result from learning, and then the synaptic weights are  modified to consolidate the change in neural activity. We demonstrate  that this distinct mechanism, in contrast to backpropagation, (1)  underlies learning in a well-established family of models of cortical  circuits, (2) enables learning that is more efficient and effective in  many contexts faced by biological organisms and (3) reproduces  surprising patterns of neural activity and behavior observed in diverse  human and rat learning experiments.&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://external-preview.redd.it/xa1vRVbxkSMbzoujivjFPZLU_RvmivHF7lmwXWaRNAI.jpg?auto=webp&amp;s=f4a87218d9fd8e33943aa130492a3836468028d5",
                                    "width": 685,
                                    "height": 296
                                },
                                "resolutions": [
                                    {
                                        "url": "https://external-preview.redd.it/xa1vRVbxkSMbzoujivjFPZLU_RvmivHF7lmwXWaRNAI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fe220e6f09601c1f4e218fd5fd153fd428c00f04",
                                        "width": 108,
                                        "height": 46
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/xa1vRVbxkSMbzoujivjFPZLU_RvmivHF7lmwXWaRNAI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=29e7594e94baa8c8196b8001c10269f9cd9fc3f3",
                                        "width": 216,
                                        "height": 93
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/xa1vRVbxkSMbzoujivjFPZLU_RvmivHF7lmwXWaRNAI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a2cc108070341bfb00b63244a34b21e3ca34fda6",
                                        "width": 320,
                                        "height": 138
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/xa1vRVbxkSMbzoujivjFPZLU_RvmivHF7lmwXWaRNAI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0f0c0652a6b3e82db631444af9a8ac1eed4499dc",
                                        "width": 640,
                                        "height": 276
                                    }
                                ],
                                "variants": {},
                                "id": "5IRjK24-0oM67Q75uMX3RsWeFCfd5x5fmCilEHup3iY"
                            }
                        ],
                        "enabled": false
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "192an1m",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "APaperADay",
                    "discussion_type": null,
                    "num_comments": 1,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/192an1m/r_inferring_neural_activity_before_plasticity_as/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/192an1m/r_inferring_neural_activity_before_plasticity_as/",
                    "subreddit_subscribers": 2854921,
                    "created_utc": 1704791684.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "Hey folks, I am looking to build internal LLM apps for different use cases. Example use cases include Product assistant, Text summarisation, Document parsing.. etc. Question: Any framework or platform to decide which LLM model to choose/pick to build these apps as per these use cases?",
                    "author_fullname": "t2_7wf04y34",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[D] Picking the right LLM model.",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_192csmj",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 5,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 5,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1704800337.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks, I am looking to build internal LLM apps for different use cases. Example use cases include Product assistant, Text summarisation, Document parsing.. etc. Question: Any framework or platform to decide which LLM model to choose/pick to build these apps as per these use cases?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "192csmj",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "vaibhavgoel2094",
                    "discussion_type": null,
                    "num_comments": 1,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/192csmj/d_picking_the_right_llm_model/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/192csmj/d_picking_the_right_llm_model/",
                    "subreddit_subscribers": 2854921,
                    "created_utc": 1704800337.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "**Paper**: [https://arxiv.org/abs/2401.01335](https://arxiv.org/abs/2401.01335)\n\n**Abstract**:\n\n&gt;Harnessing the power of human-annotated data through Supervised   Fine-Tuning (SFT) is pivotal for advancing Large Language Models (LLMs).   In this paper, we delve into the prospect of growing a strong LLM out   of a weak one without the need for acquiring additional human-annotated   data. We propose a new fine-tuning method called Self-Play fIne-tuNing   (**SPIN**), which starts from a supervised fine-tuned  model. At the heart of  SPIN lies a self-play mechanism, where the LLM  refines its capability  by playing against instances of itself. More  specifically, the LLM  generates its own training data from its previous  iterations, refining  its policy by discerning these self-generated  responses from those  obtained from human-annotated data. Our method  progressively elevates  the LLM from a nascent model to a formidable  one, unlocking the full  potential of human-annotated demonstration data  for SFT. Theoretically,  we prove that the global optimum to the  training objective function of  our method is achieved only when the LLM  policy aligns with the target  data distribution. Empirically, we  evaluate our method on several  benchmark datasets including the  HuggingFace Open LLM Leaderboard,  MT-Bench, and datasets from  Big-Bench. Our results show that SPIN can  significantly improve the  LLM's performance across a variety of  benchmarks and even outperform  models trained through direct preference  optimization (DPO)  supplemented with extra GPT-4 preference data. This  sheds light on the  promise of self-play, enabling the achievement of  human-level  performance in LLMs without the need for expert opponents.",
                    "author_fullname": "t2_mveclxvsc",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[R] Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "three",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_192agnv",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.9,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 7,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Research",
                    "can_mod_post": false,
                    "score": 7,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1704790911.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Paper&lt;/strong&gt;: &lt;a href=\"https://arxiv.org/abs/2401.01335\"&gt;https://arxiv.org/abs/2401.01335&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Harnessing the power of human-annotated data through Supervised   Fine-Tuning (SFT) is pivotal for advancing Large Language Models (LLMs).   In this paper, we delve into the prospect of growing a strong LLM out   of a weak one without the need for acquiring additional human-annotated   data. We propose a new fine-tuning method called Self-Play fIne-tuNing   (&lt;strong&gt;SPIN&lt;/strong&gt;), which starts from a supervised fine-tuned  model. At the heart of  SPIN lies a self-play mechanism, where the LLM  refines its capability  by playing against instances of itself. More  specifically, the LLM  generates its own training data from its previous  iterations, refining  its policy by discerning these self-generated  responses from those  obtained from human-annotated data. Our method  progressively elevates  the LLM from a nascent model to a formidable  one, unlocking the full  potential of human-annotated demonstration data  for SFT. Theoretically,  we prove that the global optimum to the  training objective function of  our method is achieved only when the LLM  policy aligns with the target  data distribution. Empirically, we  evaluate our method on several  benchmark datasets including the  HuggingFace Open LLM Leaderboard,  MT-Bench, and datasets from  Big-Bench. Our results show that SPIN can  significantly improve the  LLM&amp;#39;s performance across a variety of  benchmarks and even outperform  models trained through direct preference  optimization (DPO)  supplemented with extra GPT-4 preference data. This  sheds light on the  promise of self-play, enabling the achievement of  human-level  performance in LLMs without the need for expert opponents.&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "192agnv",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "APaperADay",
                    "discussion_type": null,
                    "num_comments": 0,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/192agnv/r_selfplay_finetuning_converts_weak_language/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/192agnv/r_selfplay_finetuning_converts_weak_language/",
                    "subreddit_subscribers": 2854921,
                    "created_utc": 1704790911.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "I don't understand jure leskovoc s videos. But want to learn.Where do I start?",
                    "author_fullname": "t2_pqi16q1jf",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Where do I start to study graph neural networks?[D]",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_192dgk0",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.72,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 3,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 3,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1704802755.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t understand jure leskovoc s videos. But want to learn.Where do I start?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "192dgk0",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "One_Definition_8975",
                    "discussion_type": null,
                    "num_comments": 1,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/192dgk0/where_do_i_start_to_study_graph_neural_networksd/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/192dgk0/where_do_i_start_to_study_graph_neural_networksd/",
                    "subreddit_subscribers": 2854921,
                    "created_utc": 1704802755.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "is one better than the other?",
                    "author_fullname": "t2_2z1vjz8f",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[D] reconstruction loss weight vs KLD weight for VAE's? which is better?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_192d7ml",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.64,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 3,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 3,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1704801873.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;is one better than the other?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "192d7ml",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Mr__Weasels",
                    "discussion_type": null,
                    "num_comments": 4,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/192d7ml/d_reconstruction_loss_weight_vs_kld_weight_for/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/192d7ml/d_reconstruction_loss_weight_vs_kld_weight_for/",
                    "subreddit_subscribers": 2854921,
                    "created_utc": 1704801873.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "My partner and I are working on developing a suite of models and networks to be released as an online shopping experience. We\u2019re hesitant to proceed with the project due to, what we perceive as a saturated market that our tiny operation would drown in. It is just the two of us, our big ideas, and no technical machine learning expertise.\n\nWe\u2019d like some perspective regarding the state of the industry and if pursuing our ideas (AKA beginning to heavily invest in expertise) is practical for our operation.\n\nWe want to build a sophisticated hybrid recommendation system, temperature and precipitation forecasting models, and the nuts and bolts to put everything together and make it consumer-accessible.\n\nMore details can be provided if needed. Thanks for the help.",
                    "author_fullname": "t2_b4w5wr9",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "State of the Industry and a New Business [D]",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": true,
                    "name": "t3_192m6ll",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.5,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 0,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 0,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1704826167.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My partner and I are working on developing a suite of models and networks to be released as an online shopping experience. We\u2019re hesitant to proceed with the project due to, what we perceive as a saturated market that our tiny operation would drown in. It is just the two of us, our big ideas, and no technical machine learning expertise.&lt;/p&gt;\n\n&lt;p&gt;We\u2019d like some perspective regarding the state of the industry and if pursuing our ideas (AKA beginning to heavily invest in expertise) is practical for our operation.&lt;/p&gt;\n\n&lt;p&gt;We want to build a sophisticated hybrid recommendation system, temperature and precipitation forecasting models, and the nuts and bolts to put everything together and make it consumer-accessible.&lt;/p&gt;\n\n&lt;p&gt;More details can be provided if needed. Thanks for the help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "192m6ll",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "zen_mattson",
                    "discussion_type": null,
                    "num_comments": 2,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/192m6ll/state_of_the_industry_and_a_new_business_d/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/192m6ll/state_of_the_industry_and_a_new_business_d/",
                    "subreddit_subscribers": 2854921,
                    "created_utc": 1704826167.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "\nThis post is meant to provide insight into the human brain so that it becomes easier to compare it to artificial neural networks.\n\n\nTake most of what I'm about to say with a grain of salt, I could easily be of by an order of magnitude or have missed something.\n\n1. Ray Kurzweils estimate.\n10^11 neurons.\n1000 synaptic connections per neuron.\n100 spikes per second.\n\n10^11 \u00d7 1000 \u00d7 100=10^16 calculations per second.\n\nQuote from the singularity is near:\n\"Given the early stage of human-brain reverse engineering, I will use a more conservative figure of 10^16 CPS\".\n\n\n2. My own calculation.\nThings seem to have changed since 2005, now Wikipedia says 7000 synapses per neuron \nhttps://en.m.wikipedia.org/wiki/Neuron\n\nNeuron firing speed is estimated to be 0.1 to 2 Hertz on average. https://aiimpacts.org/rate-of-neuron-firing/#:~:text=Assorted%20estimates-\n\nI will use 1/s as spike frequency. The brain is also more defined at 86,000,000,000 neurons.\n\n8,6\u00d710^10 \u00d7 7000 \u00d7 1 = 6\u00d710^14.\n6\u00d710^14 FLOPs (one FLOP per synapse).\n\n\n3. Spike energy requirement.\nEach activation of a neuron requires a certain amount of energy and that energy seems to be 2.468 \u00d7 10^\u22127 J\nhttps://link.springer.com/article/10.1007/s11571-018-9503-3\n\nSo from here everything else can be figured out.\nSpike energy = 2.468 \u00d7 10^\u22127 J\nBrain energy consumption over 24 hours = 1,673,600 joule \nSeconds in 24 hours = 86400.\n7000 synapses per neuron.\n\n1,673,600\u00f7(2.468 \u00d7 10^\u22127) J = 6,782\u00d710^12.\n6,782\u00d710^12 \u00f7 86400 = 78,486,103.\n\n(78,5 million spikes per second).\n\n78,486,103 \u00d7 7000 = 5.49\u00d710^10 FLOPs or 549 gigaFLOPs\n\nIf 3 is correct, then that would mean that a high-end phone has more compute in the GPU than the human brain (Samsung s23, 3,681 TFLOPs at fp32. Brain 0,549 TFLOPs average over the day).\n\nThis is not a good way to compare things because the brain is a massively parallel computer where the memory basically is in the structure. \n\nSo how much \"memory\" are we talking about for the brain?\nWe have:\n86,000,000,000 neurons.\n7000 synapses per neuron.\n5 bits per synapse.\nhttps://www.cnsnevada.com/what-is-the-memory-capacity-of-a-human-brain/#:~:text=Neurons%20are%20the%20cells%20which\n\n86,000,000,000 \u00d7 7000 \u00d7 5 = 3\u00d710^15 bits or 3.76\u00d710^14 bytes.\nGood luck fitting 376 terabytes of RAM on a phone.\n\nBut is 78,500,000 spikes per second really enough for the brain to process everything? Let's look at the eyes.\n\nEach eye has a total resolution of 8 megapixels.\nhttps://m.youtube.com/watch?v=4I5Q3UXkGd0&amp;pp=ygUednNhdWNlIHJlc29sdXRpb24gb2YgaHVtYW4gZXll\n\nThe information sent through the optical nerve is only about 10,000,000 bits/s \nhttps://www.eurekalert.org/news-releases/468943\n\n(only the most relevant information is sent through the optical nerve because the brain wants to conserve power at all costs).\nSo we have 20,000,000 Spikes/s for both eyes which is 25,5% of 78,5 million.\n\n78.5 million spikes is not a hard performance ceiling, it's only the average over the day and the brain is actively modulating brain-wave frequency according to need.\n\nWhich scenario is more likely in your opinion? 1. 2. or 3.",
                    "author_fullname": "t2_vbiw0uzi",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[D] Human brain FLOPs estimate, is it lower than we thought?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_191ol1n",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.79,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 131,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 131,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "self",
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1704729956.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This post is meant to provide insight into the human brain so that it becomes easier to compare it to artificial neural networks.&lt;/p&gt;\n\n&lt;p&gt;Take most of what I&amp;#39;m about to say with a grain of salt, I could easily be of by an order of magnitude or have missed something.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Ray Kurzweils estimate.\n10&lt;sup&gt;11&lt;/sup&gt; neurons.\n1000 synaptic connections per neuron.\n100 spikes per second.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;10&lt;sup&gt;11&lt;/sup&gt; \u00d7 1000 \u00d7 100=10&lt;sup&gt;16&lt;/sup&gt; calculations per second.&lt;/p&gt;\n\n&lt;p&gt;Quote from the singularity is near:\n&amp;quot;Given the early stage of human-brain reverse engineering, I will use a more conservative figure of 10&lt;sup&gt;16&lt;/sup&gt; CPS&amp;quot;.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;My own calculation.\nThings seem to have changed since 2005, now Wikipedia says 7000 synapses per neuron \n&lt;a href=\"https://en.m.wikipedia.org/wiki/Neuron\"&gt;https://en.m.wikipedia.org/wiki/Neuron&lt;/a&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Neuron firing speed is estimated to be 0.1 to 2 Hertz on average. &lt;a href=\"https://aiimpacts.org/rate-of-neuron-firing/#:%7E:text=Assorted%20estimates-\"&gt;https://aiimpacts.org/rate-of-neuron-firing/#:~:text=Assorted%20estimates-&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I will use 1/s as spike frequency. The brain is also more defined at 86,000,000,000 neurons.&lt;/p&gt;\n\n&lt;p&gt;8,6\u00d710&lt;sup&gt;10&lt;/sup&gt; \u00d7 7000 \u00d7 1 = 6\u00d710&lt;sup&gt;14.&lt;/sup&gt;\n6\u00d710&lt;sup&gt;14&lt;/sup&gt; FLOPs (one FLOP per synapse).&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Spike energy requirement.\nEach activation of a neuron requires a certain amount of energy and that energy seems to be 2.468 \u00d7 10&lt;sup&gt;\u22127&lt;/sup&gt; J\n&lt;a href=\"https://link.springer.com/article/10.1007/s11571-018-9503-3\"&gt;https://link.springer.com/article/10.1007/s11571-018-9503-3&lt;/a&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;So from here everything else can be figured out.\nSpike energy = 2.468 \u00d7 10&lt;sup&gt;\u22127&lt;/sup&gt; J\nBrain energy consumption over 24 hours = 1,673,600 joule \nSeconds in 24 hours = 86400.\n7000 synapses per neuron.&lt;/p&gt;\n\n&lt;p&gt;1,673,600\u00f7(2.468 \u00d7 10&lt;sup&gt;\u22127)&lt;/sup&gt; J = 6,782\u00d710&lt;sup&gt;12.&lt;/sup&gt;\n6,782\u00d710&lt;sup&gt;12&lt;/sup&gt; \u00f7 86400 = 78,486,103.&lt;/p&gt;\n\n&lt;p&gt;(78,5 million spikes per second).&lt;/p&gt;\n\n&lt;p&gt;78,486,103 \u00d7 7000 = 5.49\u00d710&lt;sup&gt;10&lt;/sup&gt; FLOPs or 549 gigaFLOPs&lt;/p&gt;\n\n&lt;p&gt;If 3 is correct, then that would mean that a high-end phone has more compute in the GPU than the human brain (Samsung s23, 3,681 TFLOPs at fp32. Brain 0,549 TFLOPs average over the day).&lt;/p&gt;\n\n&lt;p&gt;This is not a good way to compare things because the brain is a massively parallel computer where the memory basically is in the structure. &lt;/p&gt;\n\n&lt;p&gt;So how much &amp;quot;memory&amp;quot; are we talking about for the brain?\nWe have:\n86,000,000,000 neurons.\n7000 synapses per neuron.\n5 bits per synapse.\n&lt;a href=\"https://www.cnsnevada.com/what-is-the-memory-capacity-of-a-human-brain/#:%7E:text=Neurons%20are%20the%20cells%20which\"&gt;https://www.cnsnevada.com/what-is-the-memory-capacity-of-a-human-brain/#:~:text=Neurons%20are%20the%20cells%20which&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;86,000,000,000 \u00d7 7000 \u00d7 5 = 3\u00d710&lt;sup&gt;15&lt;/sup&gt; bits or 3.76\u00d710&lt;sup&gt;14&lt;/sup&gt; bytes.\nGood luck fitting 376 terabytes of RAM on a phone.&lt;/p&gt;\n\n&lt;p&gt;But is 78,500,000 spikes per second really enough for the brain to process everything? Let&amp;#39;s look at the eyes.&lt;/p&gt;\n\n&lt;p&gt;Each eye has a total resolution of 8 megapixels.\n&lt;a href=\"https://m.youtube.com/watch?v=4I5Q3UXkGd0&amp;amp;pp=ygUednNhdWNlIHJlc29sdXRpb24gb2YgaHVtYW4gZXll\"&gt;https://m.youtube.com/watch?v=4I5Q3UXkGd0&amp;amp;pp=ygUednNhdWNlIHJlc29sdXRpb24gb2YgaHVtYW4gZXll&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The information sent through the optical nerve is only about 10,000,000 bits/s \n&lt;a href=\"https://www.eurekalert.org/news-releases/468943\"&gt;https://www.eurekalert.org/news-releases/468943&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;(only the most relevant information is sent through the optical nerve because the brain wants to conserve power at all costs).\nSo we have 20,000,000 Spikes/s for both eyes which is 25,5% of 78,5 million.&lt;/p&gt;\n\n&lt;p&gt;78.5 million spikes is not a hard performance ceiling, it&amp;#39;s only the average over the day and the brain is actively modulating brain-wave frequency according to need.&lt;/p&gt;\n\n&lt;p&gt;Which scenario is more likely in your opinion? 1. 2. or 3.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://external-preview.redd.it/Kl_EEmBLziT9tRZwv6i53gpaopVMevQWZWdC0NlTGpM.jpg?auto=webp&amp;s=a5dc3e40c6c68fb4eb43bb47ef7b0b0663ab102c",
                                    "width": 1200,
                                    "height": 774
                                },
                                "resolutions": [
                                    {
                                        "url": "https://external-preview.redd.it/Kl_EEmBLziT9tRZwv6i53gpaopVMevQWZWdC0NlTGpM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f13855e7d4deccd49380ade9c94ac1f3a5b27a23",
                                        "width": 108,
                                        "height": 69
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/Kl_EEmBLziT9tRZwv6i53gpaopVMevQWZWdC0NlTGpM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=584e95b8e720e2b8f5db02280409cf8899787f97",
                                        "width": 216,
                                        "height": 139
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/Kl_EEmBLziT9tRZwv6i53gpaopVMevQWZWdC0NlTGpM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=155eae5fba0d816f44718deda7540c05286cc0fb",
                                        "width": 320,
                                        "height": 206
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/Kl_EEmBLziT9tRZwv6i53gpaopVMevQWZWdC0NlTGpM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2646aa8b1f33a4adaad9ad34dcf8673e3bb6a613",
                                        "width": 640,
                                        "height": 412
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/Kl_EEmBLziT9tRZwv6i53gpaopVMevQWZWdC0NlTGpM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c220cb8e84ae411a3a39fc38c374eb8606a0b3e5",
                                        "width": 960,
                                        "height": 619
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/Kl_EEmBLziT9tRZwv6i53gpaopVMevQWZWdC0NlTGpM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=68d6fdc122beee762ae2bf1a200212a54c416ad1",
                                        "width": 1080,
                                        "height": 696
                                    }
                                ],
                                "variants": {},
                                "id": "5mWkVwQHNgJthjkKNBIJsA8PjuN3rT5zL3t3iokslqQ"
                            }
                        ],
                        "enabled": false
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "191ol1n",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "SpaceXRaptor42",
                    "discussion_type": null,
                    "num_comments": 111,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/191ol1n/d_human_brain_flops_estimate_is_it_lower_than_we/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/191ol1n/d_human_brain_flops_estimate_is_it_lower_than_we/",
                    "subreddit_subscribers": 2854921,
                    "created_utc": 1704729956.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "I'm trying to build a bot from scratch using a NN and a dataset I built using chatgpt.  \nI'm having some problems with the layers.\n\n\nHere is the question I asked in StackOverflow with all the steps I took to fix it:\n https://stackoverflow.com/questions/77551635/getting-logits-and-labels-mismatch\n\nThank you for any help provided.",
                    "author_fullname": "t2_27owkay3",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Trying to build a Chat Bot with keras [P]",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "four",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": true,
                    "name": "t3_192krj0",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.5,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 0,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Project",
                    "can_mod_post": false,
                    "score": 0,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "self",
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1704822749.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to build a bot from scratch using a NN and a dataset I built using chatgpt.&lt;br/&gt;\nI&amp;#39;m having some problems with the layers.&lt;/p&gt;\n\n&lt;p&gt;Here is the question I asked in StackOverflow with all the steps I took to fix it:\n &lt;a href=\"https://stackoverflow.com/questions/77551635/getting-logits-and-labels-mismatch\"&gt;https://stackoverflow.com/questions/77551635/getting-logits-and-labels-mismatch&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thank you for any help provided.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://external-preview.redd.it/yzSfTlKTSYGpEXeFgyDvHlfoLGOFQJqPuH_Y38RBz2U.jpg?auto=webp&amp;s=a70d21ce9f01f64670d2200ca9fc3f39b94a7e48",
                                    "width": 316,
                                    "height": 316
                                },
                                "resolutions": [
                                    {
                                        "url": "https://external-preview.redd.it/yzSfTlKTSYGpEXeFgyDvHlfoLGOFQJqPuH_Y38RBz2U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0aad06750c23b98c9b7595343a8b54a42dc18851",
                                        "width": 108,
                                        "height": 108
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/yzSfTlKTSYGpEXeFgyDvHlfoLGOFQJqPuH_Y38RBz2U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b66126834977e269be586d07464046049ed09138",
                                        "width": 216,
                                        "height": 216
                                    }
                                ],
                                "variants": {},
                                "id": "nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0"
                            }
                        ],
                        "enabled": false
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "192krj0",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Obliviator77",
                    "discussion_type": null,
                    "num_comments": 0,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/192krj0/trying_to_build_a_chat_bot_with_keras_p/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/192krj0/trying_to_build_a_chat_bot_with_keras_p/",
                    "subreddit_subscribers": 2854921,
                    "created_utc": 1704822749.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "Are you guys trying any open-source model for AI dubbing?",
                    "author_fullname": "t2_z9ocs",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[D] Is there a good open-source model for dubbing?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": true,
                    "name": "t3_192kec9",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 1,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": "cd34ef9a-6abd-11ea-a7ea-0ec6041e93a9",
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 1,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1704821842.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are you guys trying any open-source model for AI dubbing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": "ML Engineer",
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "192kec9",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "paulo_zip",
                    "discussion_type": null,
                    "num_comments": 0,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": "dark",
                    "permalink": "/r/MachineLearning/comments/192kec9/d_is_there_a_good_opensource_model_for_dubbing/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/192kec9/d_is_there_a_good_opensource_model_for_dubbing/",
                    "subreddit_subscribers": 2854921,
                    "created_utc": 1704821842.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": " I am about to test the capabilities of MAMBA in a similar way to the paper [Lost in the Middle: How Language Models Use Long Contexts](https://arxiv.org/pdf/2307.03172.pdf), but as it is a lot of work, I am asking if anyone did this already. ",
                    "author_fullname": "t2_1c0nb9lo",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[R] Testing MAMBA architecture KV-Retrieval and RAG capabilities",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "three",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_192k8b4",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 1,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Research",
                    "can_mod_post": false,
                    "score": 1,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1704821437.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am about to test the capabilities of MAMBA in a similar way to the paper &lt;a href=\"https://arxiv.org/pdf/2307.03172.pdf\"&gt;Lost in the Middle: How Language Models Use Long Contexts&lt;/a&gt;, but as it is a lot of work, I am asking if anyone did this already. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "192k8b4",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "25cmderespeito",
                    "discussion_type": null,
                    "num_comments": 1,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/192k8b4/r_testing_mamba_architecture_kvretrieval_and_rag/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/192k8b4/r_testing_mamba_architecture_kvretrieval_and_rag/",
                    "subreddit_subscribers": 2854921,
                    "created_utc": 1704821437.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "I am looking for an open source model, that runs locally, which is able to translate texts from different languages into English with a high accuracy. For transcription tasks it looks like Whisper is doing very well. I was wondering if a similar model exists for text translation tasks?",
                    "author_fullname": "t2_ahc8bwem",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[Discussion] Open source model for text translation tasks?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_192ckjf",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 3,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 3,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1704799504.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for an open source model, that runs locally, which is able to translate texts from different languages into English with a high accuracy. For transcription tasks it looks like Whisper is doing very well. I was wondering if a similar model exists for text translation tasks?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "192ckjf",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Electronic-Letter592",
                    "discussion_type": null,
                    "num_comments": 1,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/192ckjf/discussion_open_source_model_for_text_translation/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/192ckjf/discussion_open_source_model_for_text_translation/",
                    "subreddit_subscribers": 2854921,
                    "created_utc": 1704799504.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "Hi all,\n\nI'm looking for a landmark paper in the field of scaling laws for llms. This is for an upper level graduate seminar which is covering a variety of topics in machine learning by reading and discussing research papers. I thought scaling laws for LLMs would be an interesting topic to cover towards the end of the course. Unfortunately it's extremely far from my own research area so I'm hoping for advice on choosing an important or particularly well written paper in the field. I'm aware of Chinchilla but I'm not sure if that's the best choice or if the field has moved past that. Any help choosing a paper or papers is appreciated! Thanks in advance!",
                    "author_fullname": "t2_45nwjfmj",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[Discussion] LLM Scaling Law Papers",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_192eids",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.67,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 2,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 2,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1704806299.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a landmark paper in the field of scaling laws for llms. This is for an upper level graduate seminar which is covering a variety of topics in machine learning by reading and discussing research papers. I thought scaling laws for LLMs would be an interesting topic to cover towards the end of the course. Unfortunately it&amp;#39;s extremely far from my own research area so I&amp;#39;m hoping for advice on choosing an important or particularly well written paper in the field. I&amp;#39;m aware of Chinchilla but I&amp;#39;m not sure if that&amp;#39;s the best choice or if the field has moved past that. Any help choosing a paper or papers is appreciated! Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "192eids",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "AmbulatingGiraffe",
                    "discussion_type": null,
                    "num_comments": 0,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/192eids/discussion_llm_scaling_law_papers/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/192eids/discussion_llm_scaling_law_papers/",
                    "subreddit_subscribers": 2854921,
                    "created_utc": 1704806299.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "https://arxiv.org/abs/2401.04088",
                    "author_fullname": "t2_pqi16q1jf",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Mixtral paper[D]",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1924vn1",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.87,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 11,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 11,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1704771112.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://arxiv.org/abs/2401.04088\"&gt;https://arxiv.org/abs/2401.04088&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "1924vn1",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "One_Definition_8975",
                    "discussion_type": null,
                    "num_comments": 1,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/1924vn1/mixtral_paperd/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/1924vn1/mixtral_paperd/",
                    "subreddit_subscribers": 2854921,
                    "created_utc": 1704771112.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "I am trying to create a table of content in the ICML 2024 latex template [(link)](https://media.icml.cc/Conferences/ICML2024/Styles/icml2024.zip) using\n\n\\\\tableofcontents\n\nbut it just creates the title \"Contents\" without actually creating any table of contents. Did anyone face similar problem or know how to resolve this?  \n[https://icml.cc/Conferences/2024/AuthorInstructions](https://icml.cc/Conferences/2024/AuthorInstructions)",
                    "author_fullname": "t2_y2y2a",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[D] tableofcontents not working in ICML 2024 template",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_192e7b9",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 2,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 2,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1704805313.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to create a table of content in the ICML 2024 latex template &lt;a href=\"https://media.icml.cc/Conferences/ICML2024/Styles/icml2024.zip\"&gt;(link)&lt;/a&gt; using&lt;/p&gt;\n\n&lt;p&gt;\\tableofcontents&lt;/p&gt;\n\n&lt;p&gt;but it just creates the title &amp;quot;Contents&amp;quot; without actually creating any table of contents. Did anyone face similar problem or know how to resolve this?&lt;br/&gt;\n&lt;a href=\"https://icml.cc/Conferences/2024/AuthorInstructions\"&gt;https://icml.cc/Conferences/2024/AuthorInstructions&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "192e7b9",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "hmi2015",
                    "discussion_type": null,
                    "num_comments": 0,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/192e7b9/d_tableofcontents_not_working_in_icml_2024/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/192e7b9/d_tableofcontents_not_working_in_icml_2024/",
                    "subreddit_subscribers": 2854921,
                    "created_utc": 1704805313.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "Hey guys, I am new to all this ML and only know a bit. I was thinking of learning this skill and I have a project planned for my summer time. long story short, it is supposed to be a portal 2 Wheatley core which can hear and respond to questions.  \n\n\nI have a few things in mind in order to achive that.  \n\n\nplease help me if you can.  \n\n\nI have a few things in mind to achieve that.  \n\n\n1)  a locally running, fine-tuned mistral model copy trained on my data, Trained to talk like Wheatley.\n\n2) a text-to-speech model for giving it the ability to speak, with EMOTIONS.  (I do wanna clone his voice)\n\n3) another model for speech-to-text.\n\n4) CV for other tasks\n\n5)  another model (which I wanna make myself using PyTorch.) that takes in the voice synthesized by the aforementioned model and spits out values of servo positions for controlling the movement.\n\n&amp;#x200B;\n\nis it possible to do this?\n\nif yes please help me (I am a 15 year old btw...)",
                    "author_fullname": "t2_g0kkuyoun",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "A Living Talking Wheatley. Project [P]",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "four",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_192iiuu",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 1,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Project",
                    "can_mod_post": false,
                    "score": 1,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1704817347.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I am new to all this ML and only know a bit. I was thinking of learning this skill and I have a project planned for my summer time. long story short, it is supposed to be a portal 2 Wheatley core which can hear and respond to questions.  &lt;/p&gt;\n\n&lt;p&gt;I have a few things in mind in order to achive that.  &lt;/p&gt;\n\n&lt;p&gt;please help me if you can.  &lt;/p&gt;\n\n&lt;p&gt;I have a few things in mind to achieve that.  &lt;/p&gt;\n\n&lt;p&gt;1)  a locally running, fine-tuned mistral model copy trained on my data, Trained to talk like Wheatley.&lt;/p&gt;\n\n&lt;p&gt;2) a text-to-speech model for giving it the ability to speak, with EMOTIONS.  (I do wanna clone his voice)&lt;/p&gt;\n\n&lt;p&gt;3) another model for speech-to-text.&lt;/p&gt;\n\n&lt;p&gt;4) CV for other tasks&lt;/p&gt;\n\n&lt;p&gt;5)  another model (which I wanna make myself using PyTorch.) that takes in the voice synthesized by the aforementioned model and spits out values of servo positions for controlling the movement.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;is it possible to do this?&lt;/p&gt;\n\n&lt;p&gt;if yes please help me (I am a 15 year old btw...)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "192iiuu",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "mego3310",
                    "discussion_type": null,
                    "num_comments": 1,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/192iiuu/a_living_talking_wheatley_project_p/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/192iiuu/a_living_talking_wheatley_project_p/",
                    "subreddit_subscribers": 2854921,
                    "created_utc": 1704817347.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": " Currently, both GPT and Gemini only support image input and do not support video input. Therefore, I selected tests related to images only from the Google Gemini demo to compare GPT-4-V and Gemini-Pro-Vision,  The tests include:  \n\n1. Basic recognition of image content\n\n2. Analysis of objects in the image \n\n3. Logical reasoning about the content in the image \n\n4. Recognition and analysis of content in consecutive images \n\n[https://youtu.be/yFK62Tn\\_f4Q](https://youtu.be/yFK62Tn_f4Q)\n\n  \n\n\n If you are interested in the open-source project demonstrated in the video, please visit [https://github.com/smalltong02/keras-llm-robot](https://github.com/smalltong02/keras-llm-robot)  \n",
                    "author_fullname": "t2_6ju7ndqu",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[D] GPT4-V VS Gemini Pro Vision Full Version!",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_19268kz",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.86,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 10,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 10,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "self",
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1704775196.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": true,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently, both GPT and Gemini only support image input and do not support video input. Therefore, I selected tests related to images only from the Google Gemini demo to compare GPT-4-V and Gemini-Pro-Vision,  The tests include:  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Basic recognition of image content&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Analysis of objects in the image &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Logical reasoning about the content in the image &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Recognition and analysis of content in consecutive images &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;a href=\"https://youtu.be/yFK62Tn_f4Q\"&gt;https://youtu.be/yFK62Tn_f4Q&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you are interested in the open-source project demonstrated in the video, please visit &lt;a href=\"https://github.com/smalltong02/keras-llm-robot\"&gt;https://github.com/smalltong02/keras-llm-robot&lt;/a&gt;  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://external-preview.redd.it/59yMTL291Xo5edkHgIlFmSSUEB11SXEUjsOutRGZY7A.jpg?auto=webp&amp;s=7525aca129ff1e17103573a0a7e0667ff1c5b4bf",
                                    "width": 480,
                                    "height": 360
                                },
                                "resolutions": [
                                    {
                                        "url": "https://external-preview.redd.it/59yMTL291Xo5edkHgIlFmSSUEB11SXEUjsOutRGZY7A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=690ef28b16b76e2e90cb839d2b446cd81dc11df0",
                                        "width": 108,
                                        "height": 81
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/59yMTL291Xo5edkHgIlFmSSUEB11SXEUjsOutRGZY7A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=64000d658a5581bc95e3ec3718333b62f5e556b4",
                                        "width": 216,
                                        "height": 162
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/59yMTL291Xo5edkHgIlFmSSUEB11SXEUjsOutRGZY7A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2efd3d32532bd276432b30fe2f871454fdca1de9",
                                        "width": 320,
                                        "height": 240
                                    }
                                ],
                                "variants": {},
                                "id": "A8Sf-5r7UlM0ju5CTIMvfzlJho6hzaUx26S-WiSLB54"
                            }
                        ],
                        "enabled": false
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "19268kz",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Entire-Fly-6957",
                    "discussion_type": null,
                    "num_comments": 3,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/19268kz/d_gpt4v_vs_gemini_pro_vision_full_version/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/19268kz/d_gpt4v_vs_gemini_pro_vision_full_version/",
                    "subreddit_subscribers": 2854921,
                    "created_utc": 1704775196.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "I have to do a project for my last semester in college. I have decided to do it on Chess. We'll be using R and Python. Any suggestions on what can be done?",
                    "author_fullname": "t2_vk5211qc",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[P] Suggestions for statistics project on Chess",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "four",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_192hbsf",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.5,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 0,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Project",
                    "can_mod_post": false,
                    "score": 0,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1704814317.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have to do a project for my last semester in college. I have decided to do it on Chess. We&amp;#39;ll be using R and Python. Any suggestions on what can be done?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "192hbsf",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "issalielmao",
                    "discussion_type": null,
                    "num_comments": 0,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/192hbsf/p_suggestions_for_statistics_project_on_chess/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/192hbsf/p_suggestions_for_statistics_project_on_chess/",
                    "subreddit_subscribers": 2854921,
                    "created_utc": 1704814317.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "I believe that in order for AI and dialogue systems to operate autonomously, they should have multimodal memories and experiences, such as scene and episodic memories.  \n(It's like the memory that appears in the movie \"After Yang\" \\[1\\])\n\nI am considering the following system for the prototype.  \nIt is a system that treats the multimodal vector DB as the system's own memory and experience, and responds to human utterances using the system's own multimodal memory.  \nThe data to be stored in the DB is assumed to be a combination of images and text related to episodic memory, such as MPCHAT \\[2\\].\n\n[Prototype](https://preview.redd.it/e95j50i3xcbc1.png?width=1972&amp;format=png&amp;auto=webp&amp;s=d33df2c158a9bb8a07a21d15b6884804d0e5f038)\n\nHowever, current multimodal LLMs are specialized in understanding images from a third-person perspective, and cannot treat images as the system's own memories or experiences.\n\nPlease let me know if there are any papers or techniques that might be helpful!  \nThank you.\n\nReferences:  \n\\[1\\] Yang's Memories Scene from AFTER YANG, [https://youtu.be/cIJ8-HGWlKw?feature=shared](https://youtu.be/cIJ8-HGWlKw?feature=shared)  \n\\[2\\] MPCHAT: Towards Multimodal Persona-Grounded Conversation, [https://arxiv.org/abs/2305.17388](https://arxiv.org/abs/2305.17388)",
                    "author_fullname": "t2_8opwsaoj",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[D] Multimodal Memory and experiences for Dialog System",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": 58,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "media_metadata": {
                        "e95j50i3xcbc1": {
                            "status": "valid",
                            "e": "Image",
                            "m": "image/png",
                            "p": [
                                {
                                    "y": 45,
                                    "x": 108,
                                    "u": "https://preview.redd.it/e95j50i3xcbc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1fb6c7e6c5b4e357f40454f4cfb1af6b299610e3"
                                },
                                {
                                    "y": 90,
                                    "x": 216,
                                    "u": "https://preview.redd.it/e95j50i3xcbc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=103e648f8966113953c1d904bceb06501c52a225"
                                },
                                {
                                    "y": 133,
                                    "x": 320,
                                    "u": "https://preview.redd.it/e95j50i3xcbc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=898a0da69dd651877e098ccc360bdc49e2bd0af2"
                                },
                                {
                                    "y": 267,
                                    "x": 640,
                                    "u": "https://preview.redd.it/e95j50i3xcbc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6bac6d1c2ac35c139939e9f57899e96f6bf8769c"
                                },
                                {
                                    "y": 401,
                                    "x": 960,
                                    "u": "https://preview.redd.it/e95j50i3xcbc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=7e2899f32514b9dad236ec98c3ec9e565755bfaf"
                                },
                                {
                                    "y": 451,
                                    "x": 1080,
                                    "u": "https://preview.redd.it/e95j50i3xcbc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7b0147833e5ab9d5a4b23a3e5e36ffce49f867ab"
                                }
                            ],
                            "s": {
                                "y": 824,
                                "x": 1972,
                                "u": "https://preview.redd.it/e95j50i3xcbc1.png?width=1972&amp;format=png&amp;auto=webp&amp;s=d33df2c158a9bb8a07a21d15b6884804d0e5f038"
                            },
                            "id": "e95j50i3xcbc1"
                        }
                    },
                    "name": "t3_1927zi6",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.88,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 6,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": 140,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 6,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "https://b.thumbs.redditmedia.com/Wx-uYpvMzqETh3_g2K2g7GnlPP7hDGKyM_IfWpBktOA.jpg",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1704781027.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I believe that in order for AI and dialogue systems to operate autonomously, they should have multimodal memories and experiences, such as scene and episodic memories.&lt;br/&gt;\n(It&amp;#39;s like the memory that appears in the movie &amp;quot;After Yang&amp;quot; [1])&lt;/p&gt;\n\n&lt;p&gt;I am considering the following system for the prototype.&lt;br/&gt;\nIt is a system that treats the multimodal vector DB as the system&amp;#39;s own memory and experience, and responds to human utterances using the system&amp;#39;s own multimodal memory.&lt;br/&gt;\nThe data to be stored in the DB is assumed to be a combination of images and text related to episodic memory, such as MPCHAT [2].&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/e95j50i3xcbc1.png?width=1972&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d33df2c158a9bb8a07a21d15b6884804d0e5f038\"&gt;Prototype&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;However, current multimodal LLMs are specialized in understanding images from a third-person perspective, and cannot treat images as the system&amp;#39;s own memories or experiences.&lt;/p&gt;\n\n&lt;p&gt;Please let me know if there are any papers or techniques that might be helpful!&lt;br/&gt;\nThank you.&lt;/p&gt;\n\n&lt;p&gt;References:&lt;br/&gt;\n[1] Yang&amp;#39;s Memories Scene from AFTER YANG, &lt;a href=\"https://youtu.be/cIJ8-HGWlKw?feature=shared\"&gt;https://youtu.be/cIJ8-HGWlKw?feature=shared&lt;/a&gt;&lt;br/&gt;\n[2] MPCHAT: Towards Multimodal Persona-Grounded Conversation, &lt;a href=\"https://arxiv.org/abs/2305.17388\"&gt;https://arxiv.org/abs/2305.17388&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "1927zi6",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "kassy11jp",
                    "discussion_type": null,
                    "num_comments": 1,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/1927zi6/d_multimodal_memory_and_experiences_for_dialog/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/1927zi6/d_multimodal_memory_and_experiences_for_dialog/",
                    "subreddit_subscribers": 2854921,
                    "created_utc": 1704781027.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            }
        ],
        "before": null
    }
}