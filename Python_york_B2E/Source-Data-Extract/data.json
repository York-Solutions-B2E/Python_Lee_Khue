{
    "kind": "Listing",
    "data": {
        "after": "t3_19agmi6",
        "dist": 26,
        "modhash": "",
        "geo_filter": null,
        "children": [
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n\nThread will stay alive until next one so keep posting after the date in the title.\n\nThanks to everyone for answering questions in the previous thread!",
                    "author_fullname": "t2_6l4z3",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[D] Simple Questions Thread",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_196j1w0",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 4,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 4,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": true,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1705248018.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!&lt;/p&gt;\n\n&lt;p&gt;Thread will stay alive until next one so keep posting after the date in the title.&lt;/p&gt;\n\n&lt;p&gt;Thanks to everyone for answering questions in the previous thread!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": "new",
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "196j1w0",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "AutoModerator",
                    "discussion_type": null,
                    "num_comments": 26,
                    "send_replies": false,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": true,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/",
                    "subreddit_subscribers": 2860548,
                    "created_utc": 1705248018.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "**Paper**: [https://arxiv.org/abs/2305.16703](https://arxiv.org/abs/2305.16703)\n\n**Abstract**:\n\n&gt;Machine Learning and Deep Learning have achieved an impressive standard  today, enabling us to answer questions that were inconceivable a few  years ago. Besides these successes, it becomes clear, that beyond pure  prediction, which is the primary strength of most supervised machine  learning algorithms, the quantification of uncertainty is relevant and  necessary as well. While first concepts and ideas in this direction have  emerged in recent years, this paper adopts a conceptual perspective and  examines possible sources of uncertainty. By adopting the viewpoint of a  statistician, we discuss the concepts of aleatoric and epistemic  uncertainty, which are more commonly associated with machine learning.  The paper aims to formalize the two types of uncertainty and  demonstrates that sources of uncertainty are miscellaneous and can not  always be decomposed into aleatoric and epistemic. Drawing parallels  between statistical concepts and uncertainty in machine learning, we  also demonstrate the role of data and their influence on uncertainty.",
                    "author_fullname": "t2_mveclxvsc",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[R] Sources of Uncertainty in Machine Learning -- A Statisticians' View",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "three",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_19aml6l",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.83,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 11,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Research",
                    "can_mod_post": false,
                    "score": 11,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1705680596.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Paper&lt;/strong&gt;: &lt;a href=\"https://arxiv.org/abs/2305.16703\"&gt;https://arxiv.org/abs/2305.16703&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Machine Learning and Deep Learning have achieved an impressive standard  today, enabling us to answer questions that were inconceivable a few  years ago. Besides these successes, it becomes clear, that beyond pure  prediction, which is the primary strength of most supervised machine  learning algorithms, the quantification of uncertainty is relevant and  necessary as well. While first concepts and ideas in this direction have  emerged in recent years, this paper adopts a conceptual perspective and  examines possible sources of uncertainty. By adopting the viewpoint of a  statistician, we discuss the concepts of aleatoric and epistemic  uncertainty, which are more commonly associated with machine learning.  The paper aims to formalize the two types of uncertainty and  demonstrates that sources of uncertainty are miscellaneous and can not  always be decomposed into aleatoric and epistemic. Drawing parallels  between statistical concepts and uncertainty in machine learning, we  also demonstrate the role of data and their influence on uncertainty.&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "19aml6l",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "APaperADay",
                    "discussion_type": null,
                    "num_comments": 1,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/19aml6l/r_sources_of_uncertainty_in_machine_learning_a/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/19aml6l/r_sources_of_uncertainty_in_machine_learning_a/",
                    "subreddit_subscribers": 2860548,
                    "created_utc": 1705680596.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "AISTATS 2024 paper acceptance results are supposed to be released today. Creating a discussion thread for this year's results.",
                    "author_fullname": "t2_4wk6mve8",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[D] AISTATS 2024 Paper Acceptance Result",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_19al3e9",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 14,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 14,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1705676627.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;AISTATS 2024 paper acceptance results are supposed to be released today. Creating a discussion thread for this year&amp;#39;s results.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "19al3e9",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "zy415",
                    "discussion_type": null,
                    "num_comments": 3,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/19al3e9/d_aistats_2024_paper_acceptance_result/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/19al3e9/d_aistats_2024_paper_acceptance_result/",
                    "subreddit_subscribers": 2860548,
                    "created_utc": 1705676627.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "  \nI have a stockpile of 22 8 GPUs servers with AMD Mi50s(see notes about Mi50s below). I've been able to get PyTorch working on these GPUs and have been able to do inference for different large language models. I originally wanted to use these GPUs to serve up LLMs, but VLLM cuda kernels don't work out of the box with the Mi50s, and Llama CPP has a bug where it only supports up to 4 AMD GPUs at once.\n\nSo TLDR, I don't want these servers sitting around and if anybody has any creative useful ideas for the servers, I'm happy to grant them SSH access to piddle around.\n\nMi50 Specs:\n\n \\- 16GB VRAM\n\n \\- 1TB/s VRAM BW\n\n \\- 25 TFLOPs",
                    "author_fullname": "t2_99ef1g34",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[D] [P] Stockpile of GPU Servers",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_19allss",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 10,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 10,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1705678030.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a stockpile of 22 8 GPUs servers with AMD Mi50s(see notes about Mi50s below). I&amp;#39;ve been able to get PyTorch working on these GPUs and have been able to do inference for different large language models. I originally wanted to use these GPUs to serve up LLMs, but VLLM cuda kernels don&amp;#39;t work out of the box with the Mi50s, and Llama CPP has a bug where it only supports up to 4 AMD GPUs at once.&lt;/p&gt;\n\n&lt;p&gt;So TLDR, I don&amp;#39;t want these servers sitting around and if anybody has any creative useful ideas for the servers, I&amp;#39;m happy to grant them SSH access to piddle around.&lt;/p&gt;\n\n&lt;p&gt;Mi50 Specs:&lt;/p&gt;\n\n&lt;p&gt;- 16GB VRAM&lt;/p&gt;\n\n&lt;p&gt;- 1TB/s VRAM BW&lt;/p&gt;\n\n&lt;p&gt;- 25 TFLOPs&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "19allss",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "TheRealBracketMaster",
                    "discussion_type": null,
                    "num_comments": 6,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/19allss/d_p_stockpile_of_gpu_servers/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/19allss/d_p_stockpile_of_gpu_servers/",
                    "subreddit_subscribers": 2860548,
                    "created_utc": 1705678030.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "",
                    "author_fullname": "t2_4bd0aw7jf",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[R] Self-Rewarding Language Models",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "three",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_19akxwp",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.8,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 9,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Research",
                    "can_mod_post": false,
                    "score": 9,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "default",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": false,
                    "mod_note": null,
                    "created": 1705676229.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "arxiv.org",
                    "allow_live_comments": false,
                    "selftext_html": null,
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "url_overridden_by_dest": "https://arxiv.org/pdf/2401.10020.pdf",
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "19akxwp",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "topcodemangler",
                    "discussion_type": null,
                    "num_comments": 0,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/19akxwp/r_selfrewarding_language_models/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://arxiv.org/pdf/2401.10020.pdf",
                    "subreddit_subscribers": 2860548,
                    "created_utc": 1705676229.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "I guess to preface, I was scrolling through Reddit when I came across this description of the game:\n\n\u201cThis game has some seriously complicated systems in it for the time. It has a chemistry system, immune systems for your creatures, behavior and personalities for them, DNA and breeding systems for them, you have to teach them actual language and words through object-word and behavior association, you have to punish and reward their behaviors correctly or they will develop maladaptive behaviors or become violent and kill your other creatures, they can become depressed too if you don't manage that, and much more. In fact, there's even an entire system of emotions in the game that they can experience and you have to try to manage that or your creatures become isolated and unresponsive to you. On top of this, there are violent and diseased races of enemy creatures called\u00a0grendels that roam the world and can kill/harass your creatures.\u201d\n\nPer the Wikipedia page:\n\n\u201cCreatures is an artificial life simulation where the user hatches small furry animals and teaches them how to behave, or leaves them to learn on their own. These \"Norns\" can talk, feed themselves, and protect themselves against vicious creatures called Grendels. It was the first popular application of machine learning in an interactive simulation. Neural networks are used by the creatures to learn what to do. The game is regarded as a breakthrough in artificial life research, which aims to model the behavior of creatures interacting with their environment.\u201d\n\nhttps://en.m.wikipedia.org/wiki/Creatures_(1996_video_game)\n\nIs there any other more advanced artificial life simulation game? These seem genuinely incredibly interesting especially with several decades of advancement in machine learning between us.",
                    "author_fullname": "t2_8qpi7etj",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[D] Creatures 1996, an early artificial life simulation game utilizing Machine Learning. Thoughts?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_19ak2w9",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.71,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 9,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 9,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "self",
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1705673772.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I guess to preface, I was scrolling through Reddit when I came across this description of the game:&lt;/p&gt;\n\n&lt;p&gt;\u201cThis game has some seriously complicated systems in it for the time. It has a chemistry system, immune systems for your creatures, behavior and personalities for them, DNA and breeding systems for them, you have to teach them actual language and words through object-word and behavior association, you have to punish and reward their behaviors correctly or they will develop maladaptive behaviors or become violent and kill your other creatures, they can become depressed too if you don&amp;#39;t manage that, and much more. In fact, there&amp;#39;s even an entire system of emotions in the game that they can experience and you have to try to manage that or your creatures become isolated and unresponsive to you. On top of this, there are violent and diseased races of enemy creatures called\u00a0grendels that roam the world and can kill/harass your creatures.\u201d&lt;/p&gt;\n\n&lt;p&gt;Per the Wikipedia page:&lt;/p&gt;\n\n&lt;p&gt;\u201cCreatures is an artificial life simulation where the user hatches small furry animals and teaches them how to behave, or leaves them to learn on their own. These &amp;quot;Norns&amp;quot; can talk, feed themselves, and protect themselves against vicious creatures called Grendels. It was the first popular application of machine learning in an interactive simulation. Neural networks are used by the creatures to learn what to do. The game is regarded as a breakthrough in artificial life research, which aims to model the behavior of creatures interacting with their environment.\u201d&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://en.m.wikipedia.org/wiki/Creatures_(1996_video_game)\"&gt;https://en.m.wikipedia.org/wiki/Creatures_(1996_video_game)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Is there any other more advanced artificial life simulation game? These seem genuinely incredibly interesting especially with several decades of advancement in machine learning between us.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://external-preview.redd.it/ElJhWU0tky2nkBG8SeYmddVFtVWpRspnSWdTfw5pNUM.jpg?auto=webp&amp;s=35a1df9be7452d28c1e1056a7d7c75dd05c8443e",
                                    "width": 295,
                                    "height": 340
                                },
                                "resolutions": [
                                    {
                                        "url": "https://external-preview.redd.it/ElJhWU0tky2nkBG8SeYmddVFtVWpRspnSWdTfw5pNUM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=09b300960fac8ad3de7a36882ac48088e03c6b3d",
                                        "width": 108,
                                        "height": 124
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/ElJhWU0tky2nkBG8SeYmddVFtVWpRspnSWdTfw5pNUM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=19ba71213d726bc8fdb475c2dd3e13c1844c3248",
                                        "width": 216,
                                        "height": 248
                                    }
                                ],
                                "variants": {},
                                "id": "C0uFlO8BWqPigqYYIIgrwBnWR-yGMxNJXFkd3wXhhTI"
                            }
                        ],
                        "enabled": false
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "19ak2w9",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Username912773",
                    "discussion_type": null,
                    "num_comments": 4,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/19ak2w9/d_creatures_1996_an_early_artificial_life/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/19ak2w9/d_creatures_1996_an_early_artificial_life/",
                    "subreddit_subscribers": 2860548,
                    "created_utc": 1705673772.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "It used to be that when you needed to train a model on some relatively niche classification/detection/segmentation task, you took a Resnet50 which was pretrained on ImageNet1K/COCO and finetuned it to whatever small-to-medium dataset you had, and that would be enough to jump-start your performance to something reasonable. Of course, you could always improve upon that by using a larger Resnet, improving your hyperparameter choices, or cleaning noise from your proprietary dataset.\n\nWell, it's been years since this practice began; newer architectures have been released, newer optimizers, we have big VL models like CLIP now, etc.. and I wonder if there's a new consensus I had missed.\n\nIf you choose to answer, I would greatly appreciate if you also elaborate in the context of the following criteria:\n\n1. Is your method of choice overly sensitive to hyperparameters? / how hard is it to converge on a proper model? For example, from my experience (which of course is not absolute), ResNets are much more forgiving than, say, EfficientNets, when it comes to hyperparameter choices.\n2. How is your method sensitive to small amounts of data? For example, I recall that the original transformer was pretty bad in the small training-set scenario, and results were reported on IN22K.\n3. How fast and/or memory-efficient is your choice? Small niche tasks don't tend to justify models with 1B parameters.\n\nThanks!",
                    "author_fullname": "t2_t8wnhftn",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[D] What is the current SOTA for bootstrapping models to work on niche tasks, in vision?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_19aet3w",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.86,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 21,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 21,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1705654622.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It used to be that when you needed to train a model on some relatively niche classification/detection/segmentation task, you took a Resnet50 which was pretrained on ImageNet1K/COCO and finetuned it to whatever small-to-medium dataset you had, and that would be enough to jump-start your performance to something reasonable. Of course, you could always improve upon that by using a larger Resnet, improving your hyperparameter choices, or cleaning noise from your proprietary dataset.&lt;/p&gt;\n\n&lt;p&gt;Well, it&amp;#39;s been years since this practice began; newer architectures have been released, newer optimizers, we have big VL models like CLIP now, etc.. and I wonder if there&amp;#39;s a new consensus I had missed.&lt;/p&gt;\n\n&lt;p&gt;If you choose to answer, I would greatly appreciate if you also elaborate in the context of the following criteria:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Is your method of choice overly sensitive to hyperparameters? / how hard is it to converge on a proper model? For example, from my experience (which of course is not absolute), ResNets are much more forgiving than, say, EfficientNets, when it comes to hyperparameter choices.&lt;/li&gt;\n&lt;li&gt;How is your method sensitive to small amounts of data? For example, I recall that the original transformer was pretty bad in the small training-set scenario, and results were reported on IN22K.&lt;/li&gt;\n&lt;li&gt;How fast and/or memory-efficient is your choice? Small niche tasks don&amp;#39;t tend to justify models with 1B parameters.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "19aet3w",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "anaccountforthemasse",
                    "discussion_type": null,
                    "num_comments": 10,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/19aet3w/d_what_is_the_current_sota_for_bootstrapping/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/19aet3w/d_what_is_the_current_sota_for_bootstrapping/",
                    "subreddit_subscribers": 2860548,
                    "created_utc": 1705654622.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "I just have learned that Facebook has archived ParlAI, the team behind BlenderBot. The repository was archived on Nov 3, 2023 and is now read-only, the project's Twitter account didn't have any update since then.\n\nSo Facebook abandoned idea behind engineered and modular dialogue system and go all in for LLM, I also heard that other modular dialogue team from other big companies are also being laid off. What do you think?",
                    "author_fullname": "t2_5d8pp5jv",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[D] Facebook shuts down ParlAI, a framework for dialogue research",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_19adrgv",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.84,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 18,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 18,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1705650202.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just have learned that Facebook has archived ParlAI, the team behind BlenderBot. The repository was archived on Nov 3, 2023 and is now read-only, the project&amp;#39;s Twitter account didn&amp;#39;t have any update since then.&lt;/p&gt;\n\n&lt;p&gt;So Facebook abandoned idea behind engineered and modular dialogue system and go all in for LLM, I also heard that other modular dialogue team from other big companies are also being laid off. What do you think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "19adrgv",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Comfortable_Use_5033",
                    "discussion_type": null,
                    "num_comments": 3,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/19adrgv/d_facebook_shuts_down_parlai_a_framework_for/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/19adrgv/d_facebook_shuts_down_parlai_a_framework_for/",
                    "subreddit_subscribers": 2860548,
                    "created_utc": 1705650202.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "**Paper**: [https://arxiv.org/abs/2305.11252](https://arxiv.org/abs/2305.11252)\n\n**Abstract**:\n\n&gt;Artificial neural networks (ANNs) have emerged as an essential tool in  machine learning, achieving remarkable success across diverse domains,  including image and speech generation, game playing, and robotics.  However, there exist fundamental differences between ANNs' operating  mechanisms and those of the biological brain, particularly concerning  learning processes. This paper presents a comprehensive review of  current brain-inspired learning representations in artificial neural  networks. We investigate the integration of more biologically plausible  mechanisms, such as synaptic plasticity, to enhance these networks'  capabilities. Moreover, we delve into the potential advantages and  challenges accompanying this approach. Ultimately, we pinpoint promising  avenues for future research in this rapidly advancing field, which  could bring us closer to understanding the essence of intelligence.",
                    "author_fullname": "t2_mveclxvsc",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[R] Brain-inspired learning in artificial neural networks: a review",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "three",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_19amch3",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 4,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Research",
                    "can_mod_post": false,
                    "score": 4,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1705679999.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Paper&lt;/strong&gt;: &lt;a href=\"https://arxiv.org/abs/2305.11252\"&gt;https://arxiv.org/abs/2305.11252&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Artificial neural networks (ANNs) have emerged as an essential tool in  machine learning, achieving remarkable success across diverse domains,  including image and speech generation, game playing, and robotics.  However, there exist fundamental differences between ANNs&amp;#39; operating  mechanisms and those of the biological brain, particularly concerning  learning processes. This paper presents a comprehensive review of  current brain-inspired learning representations in artificial neural  networks. We investigate the integration of more biologically plausible  mechanisms, such as synaptic plasticity, to enhance these networks&amp;#39;  capabilities. Moreover, we delve into the potential advantages and  challenges accompanying this approach. Ultimately, we pinpoint promising  avenues for future research in this rapidly advancing field, which  could bring us closer to understanding the essence of intelligence.&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "19amch3",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "APaperADay",
                    "discussion_type": null,
                    "num_comments": 1,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/19amch3/r_braininspired_learning_in_artificial_neural/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/19amch3/r_braininspired_learning_in_artificial_neural/",
                    "subreddit_subscribers": 2860548,
                    "created_utc": 1705679999.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "\"Self Consistency Improves of Chain of Thought Reasoning in Language Models\" (Wang et al. 2022) calculates a majority vote to determine the most consistent answer from a set of answer. They state that after sampling multiple (r\\_i ,a\\_i ), where r is the reasoning path and a is the answer, they apply a marginalization over r\\_i by taking a majority vote $argmax\\_a \\\\sum 1{a\\_i = a}$.\n\nI don't understand how the probability distribution for the indicator variable $a\\_i = a$ is calculated? Intuitively there should be some way to measure how similar $a\\_i$ is to $a$.",
                    "author_fullname": "t2_qp87vf9",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[R] [D] Self Consistency for COT majority vote calculation",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": true,
                    "name": "t3_19aquwt",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 2,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 2,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1705691110.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;Self Consistency Improves of Chain of Thought Reasoning in Language Models&amp;quot; (Wang et al. 2022) calculates a majority vote to determine the most consistent answer from a set of answer. They state that after sampling multiple (r_i ,a_i ), where r is the reasoning path and a is the answer, they apply a marginalization over r_i by taking a majority vote $argmax_a \\sum 1{a_i = a}$.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t understand how the probability distribution for the indicator variable $a_i = a$ is calculated? Intuitively there should be some way to measure how similar $a_i$ is to $a$.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "19aquwt",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "MLJungle",
                    "discussion_type": null,
                    "num_comments": 0,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/19aquwt/r_d_self_consistency_for_cot_majority_vote/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/19aquwt/r_d_self_consistency_for_cot_majority_vote/",
                    "subreddit_subscribers": 2860548,
                    "created_utc": 1705691110.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "Hi everyone, I'm an ML engineer trying to change my job but it seems like everywhere they are requiring cloud experience. Unfortunately I didn't work with clouds but I want to learn it, specifically AWS. Which AWS courses do you recommend?",
                    "author_fullname": "t2_64wzhijb",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[D] AWS courses",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_19ajjll",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 5,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 5,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1705672258.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I&amp;#39;m an ML engineer trying to change my job but it seems like everywhere they are requiring cloud experience. Unfortunately I didn&amp;#39;t work with clouds but I want to learn it, specifically AWS. Which AWS courses do you recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "19ajjll",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "lusinn",
                    "discussion_type": null,
                    "num_comments": 2,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/19ajjll/d_aws_courses/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/19ajjll/d_aws_courses/",
                    "subreddit_subscribers": 2860548,
                    "created_utc": 1705672258.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "Is Strong A.I. (General A.I.) actually a serious field of research, or is it just pure hype that came from people who just read/watched to sci-fi books?\n\nIs Strong AI/a.k.a. AGI actually being taken serious by some researchers/institutions who think that It can eventually being done, or is It another one of these fancy tech vaporwares who people are hyping till can't no more, but actually, those who are working in the field know that such an Idea can't actually work due to hard physical constraints, or If ever happens it's gonna take centuries to come into fruition?\n\nBecause there have been a Lot of hysteria in the past for many futuristic technologies, which were hyped by lots of people who didn't knew squat about It, however It could not work in practice(i.e. Em Drive, Graphene, Fulerenes, Nanobots, Bussard Ramjet, Fusion Energy, etc.).",
                    "author_fullname": "t2_8eys0i5p",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[D] Is Strong A.I. actually a serious and real field being research, or just another hype people are promoting?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_19a6nsd",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.65,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 39,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 39,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": 1705627492.0,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1705626999.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is Strong A.I. (General A.I.) actually a serious field of research, or is it just pure hype that came from people who just read/watched to sci-fi books?&lt;/p&gt;\n\n&lt;p&gt;Is Strong AI/a.k.a. AGI actually being taken serious by some researchers/institutions who think that It can eventually being done, or is It another one of these fancy tech vaporwares who people are hyping till can&amp;#39;t no more, but actually, those who are working in the field know that such an Idea can&amp;#39;t actually work due to hard physical constraints, or If ever happens it&amp;#39;s gonna take centuries to come into fruition?&lt;/p&gt;\n\n&lt;p&gt;Because there have been a Lot of hysteria in the past for many futuristic technologies, which were hyped by lots of people who didn&amp;#39;t knew squat about It, however It could not work in practice(i.e. Em Drive, Graphene, Fulerenes, Nanobots, Bussard Ramjet, Fusion Energy, etc.).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "19a6nsd",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Enzo-chan",
                    "discussion_type": null,
                    "num_comments": 226,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/19a6nsd/d_is_strong_ai_actually_a_serious_and_real_field/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/19a6nsd/d_is_strong_ai_actually_a_serious_and_real_field/",
                    "subreddit_subscribers": 2860548,
                    "created_utc": 1705626999.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "Hi, just sharing a [slide deck about PyTorch internals](https://blog.christianperone.com/2023/12/pytorch-2-internals-talk/) covering recent projects such as Dynamo, Inductor, ExecuTorch, etc, as I think there might be some folks here interested.",
                    "author_fullname": "t2_3cu3h",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[P] PyTorch 2 Internals",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "four",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_19a1mup",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 74,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Project",
                    "can_mod_post": false,
                    "score": 74,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1705613878.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, just sharing a &lt;a href=\"https://blog.christianperone.com/2023/12/pytorch-2-internals-talk/\"&gt;slide deck about PyTorch internals&lt;/a&gt; covering recent projects such as Dynamo, Inductor, ExecuTorch, etc, as I think there might be some folks here interested.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "19a1mup",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "perone",
                    "discussion_type": null,
                    "num_comments": 8,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/19a1mup/p_pytorch_2_internals/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/19a1mup/p_pytorch_2_internals/",
                    "subreddit_subscribers": 2860548,
                    "created_utc": 1705613878.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "",
                    "user_reports": [],
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[2401.10187] Fast Kronecker Matrix-Matrix Multiplication on GPUs",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": null,
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_19amot7",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.75,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 2,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "author_fullname": "t2_tipxpkia",
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": null,
                    "can_mod_post": false,
                    "score": 2,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "default",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": false,
                    "mod_note": null,
                    "crosspost_parent_list": [
                        {
                            "approved_at_utc": null,
                            "subreddit": "ElvenAINews",
                            "selftext": "",
                            "author_fullname": "t2_tipxpkia",
                            "saved": false,
                            "mod_reason_title": null,
                            "gilded": 0,
                            "clicked": false,
                            "title": "[2401.10187] Fast Kronecker Matrix-Matrix Multiplication on GPUs",
                            "link_flair_richtext": [],
                            "subreddit_name_prefixed": "r/ElvenAINews",
                            "hidden": false,
                            "pwls": null,
                            "link_flair_css_class": null,
                            "downs": 0,
                            "thumbnail_height": null,
                            "top_awarded_type": null,
                            "hide_score": false,
                            "name": "t3_19amog9",
                            "quarantine": false,
                            "link_flair_text_color": "dark",
                            "upvote_ratio": 1.0,
                            "author_flair_background_color": null,
                            "subreddit_type": "restricted",
                            "ups": 2,
                            "total_awards_received": 0,
                            "media_embed": {},
                            "thumbnail_width": null,
                            "author_flair_template_id": null,
                            "is_original_content": false,
                            "user_reports": [],
                            "secure_media": null,
                            "is_reddit_media_domain": false,
                            "is_meta": false,
                            "category": null,
                            "secure_media_embed": {},
                            "link_flair_text": null,
                            "can_mod_post": false,
                            "score": 2,
                            "approved_by": null,
                            "is_created_from_ads_ui": false,
                            "author_premium": false,
                            "thumbnail": "default",
                            "edited": false,
                            "author_flair_css_class": null,
                            "author_flair_richtext": [],
                            "gildings": {},
                            "content_categories": null,
                            "is_self": false,
                            "mod_note": null,
                            "created": 1705680811.0,
                            "link_flair_type": "text",
                            "wls": null,
                            "removed_by_category": null,
                            "banned_by": null,
                            "author_flair_type": "text",
                            "domain": "arxiv.org",
                            "allow_live_comments": false,
                            "selftext_html": null,
                            "likes": null,
                            "suggested_sort": null,
                            "banned_at_utc": null,
                            "url_overridden_by_dest": "https://arxiv.org/abs/2401.10187",
                            "view_count": null,
                            "archived": false,
                            "no_follow": false,
                            "is_crosspostable": false,
                            "pinned": false,
                            "over_18": false,
                            "all_awardings": [],
                            "awarders": [],
                            "media_only": false,
                            "can_gild": false,
                            "spoiler": false,
                            "locked": false,
                            "author_flair_text": null,
                            "treatment_tags": [],
                            "visited": false,
                            "removed_by": null,
                            "num_reports": null,
                            "distinguished": null,
                            "subreddit_id": "t5_acsk8j",
                            "author_is_blocked": false,
                            "mod_reason_by": null,
                            "removal_reason": null,
                            "link_flair_background_color": "",
                            "id": "19amog9",
                            "is_robot_indexable": true,
                            "report_reasons": null,
                            "author": "Elven77AI",
                            "discussion_type": null,
                            "num_comments": 0,
                            "send_replies": true,
                            "whitelist_status": null,
                            "contest_mode": false,
                            "mod_reports": [],
                            "author_patreon_flair": false,
                            "author_flair_text_color": null,
                            "permalink": "/r/ElvenAINews/comments/19amog9/240110187_fast_kronecker_matrixmatrix/",
                            "parent_whitelist_status": null,
                            "stickied": false,
                            "url": "https://arxiv.org/abs/2401.10187",
                            "subreddit_subscribers": 7,
                            "created_utc": 1705680811.0,
                            "num_crossposts": 1,
                            "media": null,
                            "is_video": false
                        }
                    ],
                    "created": 1705680836.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "arxiv.org",
                    "allow_live_comments": false,
                    "selftext_html": null,
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "url_overridden_by_dest": "https://arxiv.org/abs/2401.10187",
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "19amot7",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Elven77AI",
                    "discussion_type": null,
                    "num_comments": 0,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "crosspost_parent": "t3_19amog9",
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/19amot7/240110187_fast_kronecker_matrixmatrix/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://arxiv.org/abs/2401.10187",
                    "subreddit_subscribers": 2860548,
                    "created_utc": 1705680836.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "If there was a network trained to perform video upscaling/denoising as well as create intermediate frames for frame interpolation, it seems obvious that training for one task would also increase accuracy on the other. Has this been done before, is there a paper I can read that shows this result?\n\nAll the papers Ive seen so far seem to treat these 2 problems separately, such as the DAIN (Depth-Aware Video Frame Interpolation) network.",
                    "author_fullname": "t2_qjdw3areo",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[Discussion] Network that combines video upscaling with video retiming/interpolation?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_19alo6a",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 2,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 2,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1705678212.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If there was a network trained to perform video upscaling/denoising as well as create intermediate frames for frame interpolation, it seems obvious that training for one task would also increase accuracy on the other. Has this been done before, is there a paper I can read that shows this result?&lt;/p&gt;\n\n&lt;p&gt;All the papers Ive seen so far seem to treat these 2 problems separately, such as the DAIN (Depth-Aware Video Frame Interpolation) network.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "19alo6a",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Vivid-Art6939",
                    "discussion_type": null,
                    "num_comments": 0,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/19alo6a/discussion_network_that_combines_video_upscaling/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/19alo6a/discussion_network_that_combines_video_upscaling/",
                    "subreddit_subscribers": 2860548,
                    "created_utc": 1705678212.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "in 2.2. Input Representation section, it uses byte-level version of BPE, how does it handle the other language that could be handled in Unicode version?(you know there is many more characters than 256 in Unicode, so I was wondering)\n\n\\+\n\n'Since our approach can assign a probability to any Unicode string'(from the same section), and how is it possible when it could only represent 256 characters from the entire Unicode?\n\n&amp;#x200B;\n\nplease tell me if I misunderstood anything. thank you",
                    "author_fullname": "t2_byg7kn41t",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[D] GPT 2 paper question (Language Models are Unsupervised Multitask Learners)",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_19aj9is",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 2,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 2,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1705671441.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;in 2.2. Input Representation section, it uses byte-level version of BPE, how does it handle the other language that could be handled in Unicode version?(you know there is many more characters than 256 in Unicode, so I was wondering)&lt;/p&gt;\n\n&lt;p&gt;+&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;Since our approach can assign a probability to any Unicode string&amp;#39;(from the same section), and how is it possible when it could only represent 256 characters from the entire Unicode?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;please tell me if I misunderstood anything. thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "19aj9is",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "BarkingBot",
                    "discussion_type": null,
                    "num_comments": 2,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/19aj9is/d_gpt_2_paper_question_language_models_are/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/19aj9is/d_gpt_2_paper_question_language_models_are/",
                    "subreddit_subscribers": 2860548,
                    "created_utc": 1705671441.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "Hi there, I'm a senior python dev getting into LLM training. My boss is using a system that requires question and answer pairs to be fed into it.  \n\n\nIs this how all training is done? Transforming all our text data into Q&amp;A pairs is a major underpinning. I was hoping we could just feed it mountains of text and then pre-train it on this. But the current solution we are using doesn't work like this.  \n\n\nHow do you train your LLM's and what should I look at?",
                    "author_fullname": "t2_ctpid05w",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[R] How do you train your LLM's?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "three",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_19a03ax",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.77,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 41,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Research",
                    "can_mod_post": false,
                    "score": 41,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1705610144.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, I&amp;#39;m a senior python dev getting into LLM training. My boss is using a system that requires question and answer pairs to be fed into it.  &lt;/p&gt;\n\n&lt;p&gt;Is this how all training is done? Transforming all our text data into Q&amp;amp;A pairs is a major underpinning. I was hoping we could just feed it mountains of text and then pre-train it on this. But the current solution we are using doesn&amp;#39;t work like this.  &lt;/p&gt;\n\n&lt;p&gt;How do you train your LLM&amp;#39;s and what should I look at?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "19a03ax",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "ZachVorhies",
                    "discussion_type": null,
                    "num_comments": 31,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/19a03ax/r_how_do_you_train_your_llms/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/19a03ax/r_how_do_you_train_your_llms/",
                    "subreddit_subscribers": 2860548,
                    "created_utc": 1705610144.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "I have a dataset of approximately 100k different products. These products can either be whole units or accessories. Like complete computers vs buying cases, mouse, keyboard, ram, cpu etc.\n\nI want to build a recommendation system that finds similar products given the input of 1 product.\n\nThe data is tabular (price, length/width/height, category, subtype, etc. with some text portions like title and description that can be variable\u2026 there are some columns 100% in common across everything but different categories have different specifications/columns)\n\nEventually this will go on a website - but assume 0 user traffic right now. Which I think rules out collaborative filtering since there\u2019s no feedback loop. Although long term that\u2019s probably ideal.\n\nSince it\u2019s tabular data, can I use XGBoost? Do I BM25 any free form text fields and covert categories/types to numbers? Or is embeddings + kNN better? Any YouTube videos or documentation would help.\n\nI\u2019m also considering having multiple separate recommendation match providers based on category since their columns differ. Similar to how StockX has recommendations based on shoes, or clothes etc.",
                    "author_fullname": "t2_1sa7j8",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[P] Cold start recommendations - XGBoost or something else?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "four",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_19ancq9",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.6,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 1,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Project",
                    "can_mod_post": false,
                    "score": 1,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1705682473.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a dataset of approximately 100k different products. These products can either be whole units or accessories. Like complete computers vs buying cases, mouse, keyboard, ram, cpu etc.&lt;/p&gt;\n\n&lt;p&gt;I want to build a recommendation system that finds similar products given the input of 1 product.&lt;/p&gt;\n\n&lt;p&gt;The data is tabular (price, length/width/height, category, subtype, etc. with some text portions like title and description that can be variable\u2026 there are some columns 100% in common across everything but different categories have different specifications/columns)&lt;/p&gt;\n\n&lt;p&gt;Eventually this will go on a website - but assume 0 user traffic right now. Which I think rules out collaborative filtering since there\u2019s no feedback loop. Although long term that\u2019s probably ideal.&lt;/p&gt;\n\n&lt;p&gt;Since it\u2019s tabular data, can I use XGBoost? Do I BM25 any free form text fields and covert categories/types to numbers? Or is embeddings + kNN better? Any YouTube videos or documentation would help.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m also considering having multiple separate recommendation match providers based on category since their columns differ. Similar to how StockX has recommendations based on shoes, or clothes etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "19ancq9",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "pegasi320",
                    "discussion_type": null,
                    "num_comments": 3,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/19ancq9/p_cold_start_recommendations_xgboost_or_something/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/19ancq9/p_cold_start_recommendations_xgboost_or_something/",
                    "subreddit_subscribers": 2860548,
                    "created_utc": 1705682473.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "Short intro - Hello! I'm a masters student with major in AI and have secured few thesis topics. I have a modest research experience and want to pursue a PhD after my masters (more inclined towards an industrial phd position).\n\nI have secured few positions where my thesis topics are listed below (I received 8 offers but I'm considering these 4 keeping my interests in mind). As thesis plays a cruicial role for phd applications as well as job application, I want a topic which is well relevant and has a potential prospect. (Ofc can't share exact title and details.) \n\n1. Video segmentation on a fairly new dataset, no papers on the methodology yet (medical) (in industry)\n\n2. Frame interpolation for videos (medical - surgery) (in industry)\n\n3. Making synthetic dataset using diffusion models (medical) (in university under infamous Prof.) \n\n4. 3D to 2D mapping using transformers (autonomous driving) (industry)\n\nAny insights on these topics might be useful. Thanks!",
                    "author_fullname": "t2_c2ajt49e",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[R] Seeking insights on my possible thesis topics!",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "three",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_19alf6m",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.33,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 0,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Research",
                    "can_mod_post": false,
                    "score": 0,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1705677531.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Short intro - Hello! I&amp;#39;m a masters student with major in AI and have secured few thesis topics. I have a modest research experience and want to pursue a PhD after my masters (more inclined towards an industrial phd position).&lt;/p&gt;\n\n&lt;p&gt;I have secured few positions where my thesis topics are listed below (I received 8 offers but I&amp;#39;m considering these 4 keeping my interests in mind). As thesis plays a cruicial role for phd applications as well as job application, I want a topic which is well relevant and has a potential prospect. (Ofc can&amp;#39;t share exact title and details.) &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Video segmentation on a fairly new dataset, no papers on the methodology yet (medical) (in industry)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Frame interpolation for videos (medical - surgery) (in industry)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Making synthetic dataset using diffusion models (medical) (in university under infamous Prof.) &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;3D to 2D mapping using transformers (autonomous driving) (industry)&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any insights on these topics might be useful. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "19alf6m",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "ade17_in",
                    "discussion_type": null,
                    "num_comments": 0,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/19alf6m/r_seeking_insights_on_my_possible_thesis_topics/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/19alf6m/r_seeking_insights_on_my_possible_thesis_topics/",
                    "subreddit_subscribers": 2860548,
                    "created_utc": 1705677531.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "What happens if you get accepted to multiple workshops at the same conference? Is there an option to withdraw from the workshop and choose the one you want to participate in?",
                    "author_fullname": "t2_885nhuwf",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[D] Multiple Workshop",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_19ajo5r",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 1,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 1,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1705672621.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What happens if you get accepted to multiple workshops at the same conference? Is there an option to withdraw from the workshop and choose the one you want to participate in?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "19ajo5r",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "BigDreamx",
                    "discussion_type": null,
                    "num_comments": 0,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/19ajo5r/d_multiple_workshop/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/19ajo5r/d_multiple_workshop/",
                    "subreddit_subscribers": 2860548,
                    "created_utc": 1705672621.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "Hello,\n\nI've got something similar to press releases and I'd need to extract event information.I'm looking for events from one specific industry. But the press releases can contain none, one or mutliple event details and they don't neecessarily relate to my industry.\n\nAs a human, I'd go through the PRcheck each event infoand based on the title (sometimes the description) decide whether it's for my industryand then look for the details (date / time / location / event name / description / etc).\n\nWhat would be a good approach to do this offline / locally?I just tried around with llama.cpp and that just gives me a mess (probably I've done it wrong).A few years ago, I've used Spacy for NER - which is basically just a small part of step 4 I guess.Is there something that \"understands\" my data better and gives me great results?",
                    "author_fullname": "t2_3b3qn",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[D] How to extract event information from unstructured text?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_19abdeo",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.72,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 3,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 3,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1705641285.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve got something similar to press releases and I&amp;#39;d need to extract event information.I&amp;#39;m looking for events from one specific industry. But the press releases can contain none, one or mutliple event details and they don&amp;#39;t neecessarily relate to my industry.&lt;/p&gt;\n\n&lt;p&gt;As a human, I&amp;#39;d go through the PRcheck each event infoand based on the title (sometimes the description) decide whether it&amp;#39;s for my industryand then look for the details (date / time / location / event name / description / etc).&lt;/p&gt;\n\n&lt;p&gt;What would be a good approach to do this offline / locally?I just tried around with llama.cpp and that just gives me a mess (probably I&amp;#39;ve done it wrong).A few years ago, I&amp;#39;ve used Spacy for NER - which is basically just a small part of step 4 I guess.Is there something that &amp;quot;understands&amp;quot; my data better and gives me great results?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "19abdeo",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Chris8080",
                    "discussion_type": null,
                    "num_comments": 4,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/19abdeo/d_how_to_extract_event_information_from/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/19abdeo/d_how_to_extract_event_information_from/",
                    "subreddit_subscribers": 2860548,
                    "created_utc": 1705641285.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "Anyone building NLI architectures with NER ideas?\n\nSo I\u2019ve been going through a bunch of literature on NER and NLI and I realized that a lot of the underlying operations are basically around manipulating the masking strategies on the tokens. I\u2019m looking for folks to brainstorm new architectures in this regard. \n\nI\u2019m thinking of something like this:\n\n1. BERT layer to generate token.\n\n2. NER masking layer to generate NER relationships between the tokens (kind of acts as rationale extraction and additional signals)\n\n3. NLI logit estimation that can take advantage of all this.",
                    "author_fullname": "t2_d56m4",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[D] - Anyone using NER masking techniques in NLI architectures ?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_19aersk",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 2,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 2,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1705654459.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone building NLI architectures with NER ideas?&lt;/p&gt;\n\n&lt;p&gt;So I\u2019ve been going through a bunch of literature on NER and NLI and I realized that a lot of the underlying operations are basically around manipulating the masking strategies on the tokens. I\u2019m looking for folks to brainstorm new architectures in this regard. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m thinking of something like this:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;BERT layer to generate token.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;NER masking layer to generate NER relationships between the tokens (kind of acts as rationale extraction and additional signals)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;NLI logit estimation that can take advantage of all this.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "19aersk",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "testuser514",
                    "discussion_type": null,
                    "num_comments": 0,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/19aersk/d_anyone_using_ner_masking_techniques_in_nli/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/19aersk/d_anyone_using_ner_masking_techniques_in_nli/",
                    "subreddit_subscribers": 2860548,
                    "created_utc": 1705654459.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "I've been following [Annotated Transformer](https://nlp.seas.harvard.edu/annotated-transformer/) to implement the transformer architecture. In the multi-head attention class's `forward()` method, Query, Key &amp; Value are being multiplied with corresponding projection matrix; `W_q, W_k, W_v`.\n\n            query, key, value = [\n                lin(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n                for lin, x in zip(self.linears, (query, key, value))\n            ]\n\nHere, `lin(x)` is being reshaped into `(nbatches, -1, self.h, self.d_k)`and dimension 1 &amp; 2 is being transposed which makes the dimension `(nbatches, self.h, -1, self.d_k).`\n\nI'm failing to understand why don't they directly do `lin(x).view(nbatches, self.h, -1, self.d_k)`?",
                    "author_fullname": "t2_7wbpamj7",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[D] Transformer multi-head attention implementation",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_19a8klj",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.75,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 6,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 6,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1705632515.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been following &lt;a href=\"https://nlp.seas.harvard.edu/annotated-transformer/\"&gt;Annotated Transformer&lt;/a&gt; to implement the transformer architecture. In the multi-head attention class&amp;#39;s &lt;code&gt;forward()&lt;/code&gt; method, Query, Key &amp;amp; Value are being multiplied with corresponding projection matrix; &lt;code&gt;W_q, W_k, W_v&lt;/code&gt;.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;        query, key, value = [\n            lin(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n            for lin, x in zip(self.linears, (query, key, value))\n        ]\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Here, &lt;code&gt;lin(x)&lt;/code&gt; is being reshaped into &lt;code&gt;(nbatches, -1, self.h, self.d_k)&lt;/code&gt;and dimension 1 &amp;amp; 2 is being transposed which makes the dimension &lt;code&gt;(nbatches, self.h, -1, self.d_k).&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m failing to understand why don&amp;#39;t they directly do &lt;code&gt;lin(x).view(nbatches, self.h, -1, self.d_k)&lt;/code&gt;?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "",
                    "id": "19a8klj",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Melodic_Stomach_2704",
                    "discussion_type": null,
                    "num_comments": 1,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/19a8klj/d_transformer_multihead_attention_implementation/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/19a8klj/d_transformer_multihead_attention_implementation/",
                    "subreddit_subscribers": 2860548,
                    "created_utc": 1705632515.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "I would like to share a project I have worked on recently, using XGBoost Classifiers, Flask API, Docker, Google Cloud Container Registry and Google Cloud run. Feel free to comment if it interests you:\n\n[https://christiangrech.medium.com/building-a-robust-dutch-nlp-symptom-checker-from-data-to-deployment-e389d874a247](https://christiangrech.medium.com/building-a-robust-dutch-nlp-symptom-checker-from-data-to-deployment-e389d874a247)",
                    "author_fullname": "t2_17dclv",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[P] NLP Symptom Checker for Dutch Speakers: From Data to Deployment",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "four",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_19ahe92",
                    "quarantine": false,
                    "link_flair_text_color": null,
                    "upvote_ratio": 0.67,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 1,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Project",
                    "can_mod_post": false,
                    "score": 1,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "self",
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1705665186.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to share a project I have worked on recently, using XGBoost Classifiers, Flask API, Docker, Google Cloud Container Registry and Google Cloud run. Feel free to comment if it interests you:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://christiangrech.medium.com/building-a-robust-dutch-nlp-symptom-checker-from-data-to-deployment-e389d874a247\"&gt;https://christiangrech.medium.com/building-a-robust-dutch-nlp-symptom-checker-from-data-to-deployment-e389d874a247&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://external-preview.redd.it/jafozKqf2dHvX37Zhqe5-02vl5FNXGzxVMvpbaQN3lM.jpg?auto=webp&amp;s=d31f20b45feabb7e11051755bc7f99cd7ff554d9",
                                    "width": 756,
                                    "height": 758
                                },
                                "resolutions": [
                                    {
                                        "url": "https://external-preview.redd.it/jafozKqf2dHvX37Zhqe5-02vl5FNXGzxVMvpbaQN3lM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=154373ec6b75b356b282eabbcd18b118bc8a3150",
                                        "width": 108,
                                        "height": 108
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/jafozKqf2dHvX37Zhqe5-02vl5FNXGzxVMvpbaQN3lM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4e94caa8f61b1a1954c4c1861620857baeb2dac3",
                                        "width": 216,
                                        "height": 216
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/jafozKqf2dHvX37Zhqe5-02vl5FNXGzxVMvpbaQN3lM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5da9f257e6ca7d4aa4c2431573629e7245a20890",
                                        "width": 320,
                                        "height": 320
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/jafozKqf2dHvX37Zhqe5-02vl5FNXGzxVMvpbaQN3lM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1983de0254e993238053b88a33cc3d15cb249e62",
                                        "width": 640,
                                        "height": 641
                                    }
                                ],
                                "variants": {},
                                "id": "AfrMrFGuaKU9IHx06vXKcxtcaeSmD7K4g118UyADa1M"
                            }
                        ],
                        "enabled": false
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": null,
                    "id": "19ahe92",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "OutplayOutlast",
                    "discussion_type": null,
                    "num_comments": 0,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/19ahe92/p_nlp_symptom_checker_for_dutch_speakers_from/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/19ahe92/p_nlp_symptom_checker_for_dutch_speakers_from/",
                    "subreddit_subscribers": 2860548,
                    "created_utc": 1705665186.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "I have a few years of industry experience. Although I'm not an expert in deep learning (or ML in general), I know how to build models and deploy them, etc. This field is constantly evolving, so I have to keep learning. I do this with the help of YouTube or blogs, which provide me with a basic understanding of the landscape, nothing more than that.\n\nI implement a few projects here and there to gain some understanding of what I've just learned. However, with the knowledge I've acquired, I can only build the basics and don't understand how to scale it further or undertake complex projects.\n\nFor example (this is in CV but gives the gist), when learning about image segmentation, it took me around 2 weeks to learn and implement a model on this fancy data I had, which was fun. Now, without any \"need\" to develop further, that model is just a pet project. While I learned how to train and implement a custom model (UNet from scratch) and handle data on GPU, I now don't know where to look for more.\n\nI am switching to NLP because that's where I think I would like to work. However, here I see that most of the game depends on APIs and not custom model building. I don\u2019t want to build just a basic project in few days. \n\nDo you have any recommendations for projects/papers that I can implement on my own, providing proper basic knowledge of the NLP field? (like implementing a transformer model from scratch, but for advanced levels)\n\nPS: I want to implement these projects in my free time (other than my job), and on my own. So, hardware requirements might restrict me. Also, I am aware that I know very little about the NLP landscape, so any subfield that is interesting and contains theoretical background would be beneficial (I want to learn theoretical side by side :)",
                    "author_fullname": "t2_qahuu1kv",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[R] How to gain intermediate/advanced knowledge in NLP?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "three",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_19adf04",
                    "quarantine": false,
                    "link_flair_text_color": null,
                    "upvote_ratio": 0.71,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 3,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Research",
                    "can_mod_post": false,
                    "score": 3,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1705648769.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a few years of industry experience. Although I&amp;#39;m not an expert in deep learning (or ML in general), I know how to build models and deploy them, etc. This field is constantly evolving, so I have to keep learning. I do this with the help of YouTube or blogs, which provide me with a basic understanding of the landscape, nothing more than that.&lt;/p&gt;\n\n&lt;p&gt;I implement a few projects here and there to gain some understanding of what I&amp;#39;ve just learned. However, with the knowledge I&amp;#39;ve acquired, I can only build the basics and don&amp;#39;t understand how to scale it further or undertake complex projects.&lt;/p&gt;\n\n&lt;p&gt;For example (this is in CV but gives the gist), when learning about image segmentation, it took me around 2 weeks to learn and implement a model on this fancy data I had, which was fun. Now, without any &amp;quot;need&amp;quot; to develop further, that model is just a pet project. While I learned how to train and implement a custom model (UNet from scratch) and handle data on GPU, I now don&amp;#39;t know where to look for more.&lt;/p&gt;\n\n&lt;p&gt;I am switching to NLP because that&amp;#39;s where I think I would like to work. However, here I see that most of the game depends on APIs and not custom model building. I don\u2019t want to build just a basic project in few days. &lt;/p&gt;\n\n&lt;p&gt;Do you have any recommendations for projects/papers that I can implement on my own, providing proper basic knowledge of the NLP field? (like implementing a transformer model from scratch, but for advanced levels)&lt;/p&gt;\n\n&lt;p&gt;PS: I want to implement these projects in my free time (other than my job), and on my own. So, hardware requirements might restrict me. Also, I am aware that I know very little about the NLP landscape, so any subfield that is interesting and contains theoretical background would be beneficial (I want to learn theoretical side by side :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": null,
                    "id": "19adf04",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Amazing_Life_221",
                    "discussion_type": null,
                    "num_comments": 2,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/19adf04/r_how_to_gain_intermediateadvanced_knowledge_in/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/19adf04/r_how_to_gain_intermediateadvanced_knowledge_in/",
                    "subreddit_subscribers": 2860548,
                    "created_utc": 1705648769.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": " Hi!\n\nI\u2019ve been wanting to fine tune this model based on transcribed zoom interviews I have as training data.\n\nHow do I approach this problem?  \n\n\nHow do I format the dataset? What's a good methology? What GPU will I need? Lastly, how do I upload it to huggingspace as a chat UI?",
                    "author_fullname": "t2_60h62h8i",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[D] Mistral 7B FineTuning with Interview Data",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "one",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_19agmi6",
                    "quarantine": false,
                    "link_flair_text_color": null,
                    "upvote_ratio": 0.67,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 1,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 1,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1705662254.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": true,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been wanting to fine tune this model based on transcribed zoom interviews I have as training data.&lt;/p&gt;\n\n&lt;p&gt;How do I approach this problem?  &lt;/p&gt;\n\n&lt;p&gt;How do I format the dataset? What&amp;#39;s a good methology? What GPU will I need? Lastly, how do I upload it to huggingspace as a chat UI?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": false,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": null,
                    "id": "19agmi6",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "portmanteau98",
                    "discussion_type": null,
                    "num_comments": 1,
                    "send_replies": true,
                    "whitelist_status": "all_ads",
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/19agmi6/d_mistral_7b_finetuning_with_interview_data/",
                    "parent_whitelist_status": "all_ads",
                    "stickied": false,
                    "url": "https://www.reddit.com/r/MachineLearning/comments/19agmi6/d_mistral_7b_finetuning_with_interview_data/",
                    "subreddit_subscribers": 2860548,
                    "created_utc": 1705662254.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            }
        ],
        "before": null
    }
}